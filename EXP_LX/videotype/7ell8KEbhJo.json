{"label": "education", "transcript": [{"text": "\u00ab\u00a0C\u2019est incroyable, ChatGPT est une intelligence\nartificielle consciente\u00a0\u00bb", "start": 0.149, "duration": 3.86}, {"text": "\u00ab\u00a0C\u2019est nul, il r\u00e9p\u00e8te des trucs faux\nlu sur Internet, et il ne sait m\u00eame faire", "start": 4.009, "duration": 4.981}, {"text": "12 + 33\u00a0\u00bb", "start": 8.99, "duration": 1.13}, {"text": "Oui, je sais, tout le monde a d\u00e9j\u00e0 beaucoup\nparl\u00e9 de ChatGPT. Et la plupart des r\u00e9actions", "start": 10.12, "duration": 5.32}, {"text": "qu\u2019on trouve dans la presse ou sur les r\u00e9seaux\nsociaux ont tendance \u00e0 tomber dans un extr\u00eame", "start": 15.44, "duration": 4.53}, {"text": "ou un autre, en se basant juste sur quelques\nexemples bien choisis. Mais si on allait un", "start": 19.97, "duration": 5.26}, {"text": "peu plus loin ?", "start": 25.23, "duration": 1.0}, {"text": "Dans une vid\u00e9o pr\u00e9c\u00e9dente, j\u2019avais d\u00e9j\u00e0\ntrait\u00e9 la question de ces algorithmes qui", "start": 26.23, "duration": 4.45}, {"text": "savent manipuler des mots, des phrases, des\ntextes; ce domaine qu\u2019on appelle le traitement", "start": 30.68, "duration": 4.719}, {"text": "du langage naturel. Et \u00e0 l\u2019\u00e9poque j\u2019avais\nnotamment parl\u00e9 du fameux mod\u00e8le GPT d\u2019OpenAI.", "start": 35.399, "duration": 6.061}, {"text": "Mais c\u2019\u00e9tait en novembre 2021, et donc\navant la d\u00e9ferlante ChatGPT.", "start": 41.46, "duration": 5.24}, {"text": "Car oui, GPT et ChatGPT c\u2019est pas tout \u00e0\nfait pareil. Et aujourd\u2019hui, je voudrais", "start": 46.7, "duration": 5.499}, {"text": "justement faire la lumi\u00e8re sur le fonctionnement\net la diff\u00e9rence qu\u2019il existe entre ChatGPT,", "start": 52.199, "duration": 4.851}, {"text": "qui est en quelque sorte le produit commercial\nd\u2019OpenAI, et GPT qui est le mod\u00e8le d\u2019intelligence", "start": 57.05, "duration": 5.3}, {"text": "artificielle qui lui sert de base.", "start": 62.35, "duration": 2.029}, {"text": "Et je suis persuad\u00e9 qu\u2019en comprenant un\npeu mieux tout cela, \u00e7a permettra d\u2019avoir", "start": 64.379, "duration": 4.121}, {"text": "un regard plus affin\u00e9 sur les questions que\npose ChatGPT, les possibilit\u00e9s qu\u2019il offre,", "start": 68.5, "duration": 5.17}, {"text": "les dangers qu\u2019il repr\u00e9sente, et sur ce\nqu\u2019il faut en attendre, ou au contraire", "start": 73.67, "duration": 4.07}, {"text": "ne pas en attendre. Alors c\u2019est parti.", "start": 77.74, "duration": 1.379}, {"text": "Mais avant \u00e7a je voudrais vous parler d\u2019un\nsuper VPN que j\u2019utilise\u2026non je d\u00e9conne.", "start": 79.119, "duration": 4.051}, {"text": "Par contre je profite de cette interruption\npour vous inviter \u00e0 rejoindre le serveur", "start": 83.17, "duration": 4.43}, {"text": "Discord que j\u2019ai cr\u00e9\u00e9, le lien est en\ndescription. Et c\u2019est le meilleur moyen", "start": 87.6, "duration": 3.27}, {"text": "de venir prolonger la discussion, papoter,\nposer des questions \u00e0 moi ou \u00e0 d\u2019autres", "start": 90.87, "duration": 3.74}, {"text": "etc. Venez c\u2019est sympa. Fin de la parenth\u00e8se.\nRevenons \u00e0 ChatGPT.", "start": 94.61, "duration": 2.06}, {"text": "Comme vous le savez sans doute, ChatGPT c\u2019est\nun chatbot, un \u00ab\u00a0agent conversationnel\u00a0\u00bb", "start": 96.67, "duration": 4.79}, {"text": "en bon fran\u00e7ais, c\u2019est-\u00e0-dire un programme\nqui se propose de dialoguer avec vous, notamment", "start": 101.46, "duration": 4.53}, {"text": "dans le but de vous renseigner ou vous aider.\nLes chatbots \u00e7a existe depuis longtemps,", "start": 105.99, "duration": 4.629}, {"text": "et la plupart fonctionnent selon un principe\nde d\u00e9tection de mot-cl\u00e9s.", "start": 110.619, "duration": 3.591}, {"text": "[MIA On en trouve par exemple sur certains\nsites Internet pour faire de l\u2019assistance,", "start": 114.21, "duration": 4.8}, {"text": "et \u00e7a marche plus ou moins bien on va dire.\nIl faut vraiment tomber sur les bons mots-cl\u00e9s", "start": 119.01, "duration": 6.3}, {"text": "pour que l\u2019\u00e9change soit utile.]", "start": 125.31, "duration": 3.33}, {"text": "Mais depuis quelques ann\u00e9es, il devient possible\nde d\u00e9velopper des chatbots qui ne sont plus", "start": 128.64, "duration": 5.67}, {"text": "programm\u00e9s \u00e0 la main, \u00e0 partir de mots-cl\u00e9s\nd\u00e9finis \u00e0 l\u2019avance, mais en utilisant", "start": 134.31, "duration": 4.47}, {"text": "des mod\u00e8les issus de cette branche de l\u2019intelligence\nartificielle qu\u2019on appelle le \u00ab\u00a0machine", "start": 138.78, "duration": 4.26}, {"text": "learning.\u00a0\u00bb", "start": 143.04, "duration": 1.0}, {"text": "J\u2019en ai souvent parl\u00e9, l\u2019approche la\nplus fr\u00e9quente en machine learning c\u2019est", "start": 144.04, "duration": 2.981}, {"text": "ce qu\u2019on appelle l\u2019apprentissage supervis\u00e9.\nRappelons vite-fait l\u2019exemple classique", "start": 147.021, "duration": 4.489}, {"text": "de la reconnaissance d\u2019image. Imaginons\nqu\u2019on veuille fabriquer un algorithme qui", "start": 151.51, "duration": 3.759}, {"text": "sache reconnaitre ce qu\u2019il y a sur une image.", "start": 155.269, "duration": 2.881}, {"text": "[SUPERVISE On choisit un mod\u00e8le avec plein\nde param\u00e8tres, \u00e0 qui on peut pr\u00e9senter", "start": 158.15, "duration": 4.22}, {"text": "une image en entr\u00e9e, et qui va produire un\nmot en sortie. Initialement le mod\u00e8le va", "start": 162.37, "duration": 4.68}, {"text": "raconter n\u2019importe quoi, mais on va progressivement\nl\u2019entrainer en lui pr\u00e9sentant plein d\u2019exemples", "start": 167.05, "duration": 5.04}, {"text": "de ce qu\u2019on souhaite qu\u2019il fasse.", "start": 172.09, "duration": 1.77}, {"text": "On prend une grosse base de donn\u00e9es d\u2019images\nqui sont d\u00e9j\u00e0 classifi\u00e9es, on pr\u00e9sente", "start": 173.86, "duration": 4.549}, {"text": "successivement ces exemples \u00e0 notre mod\u00e8le,\net on ajuste ses param\u00e8tres pour qu\u2019il", "start": 178.409, "duration": 4.421}, {"text": "produise le maximum de bonnes r\u00e9ponses. C\u2019est\nce qu\u2019on appelle la phase d\u2019entrainement,", "start": 182.83, "duration": 4.2}, {"text": "qui peut durer assez longtemps, et qui demande\nsouvent beaucoup de donn\u00e9es.", "start": 187.03, "duration": 3.039}, {"text": "Une fois que c\u2019est fait, le mod\u00e8le est\ndonc entrain\u00e9, et il peut \u00eatre utilis\u00e9.", "start": 190.069, "duration": 3.941}, {"text": "Si l\u2019entrainement a \u00e9t\u00e9 un succ\u00e8s, quand\non lui pr\u00e9sentera ensuite des images qu\u2019il", "start": 194.01, "duration": 3.949}, {"text": "n\u2019a jamais vues, notre mod\u00e8le devrait leur\nassocier la bonne classification.]", "start": 197.959, "duration": 4.321}, {"text": "Ce principe d\u2019apprentissage supervis\u00e9 a\nd\u00e9j\u00e0 des tas d\u2019applications concr\u00e8tes,", "start": 202.28, "duration": 4.65}, {"text": "comme la reconnaissance d\u2019image, la d\u00e9tection\nde fraude ou de spam, etc. Alors intuitivement,", "start": 206.93, "duration": 5.35}, {"text": "si on veut faire un chatbot, on se dit qu\u2019on\npourrait avoir la m\u00eame approche.", "start": 212.28, "duration": 3.31}, {"text": "Un chatbot est cens\u00e9 nous fournir certaines\nr\u00e9ponses pertinentes quand on lui pose des", "start": 215.59, "duration": 4.61}, {"text": "questions. Donc on pourrait entrainer un mod\u00e8le\n\u00e0 partir d\u2019une base de donn\u00e9es de questions/r\u00e9ponses", "start": 220.2, "duration": 5.41}, {"text": "existantes, en esp\u00e9rant qu\u2019ainsi il apprenne\n\u00e0 r\u00e9pondre intelligemment \u00e0 n\u2019importe", "start": 225.61, "duration": 4.989}, {"text": "quel type de requ\u00eate.", "start": 230.599, "duration": 1.0}, {"text": "Le probl\u00e8me, c\u2019est que cette approche n\u2019est\npas tr\u00e8s efficace. On peut citer plusieurs", "start": 231.599, "duration": 4.36}, {"text": "raisons. D\u00e9j\u00e0 pour que \u00e7a marche, il faudrait\nune \u00e9norme quantit\u00e9 de donn\u00e9es, c\u2019est", "start": 235.959, "duration": 4.56}, {"text": "\u00e0 dire un grand nombre d\u2019\u00e9changes questions/r\u00e9ponses.\nIl faudrait que \u00e7a couvre un maximum de sujets,", "start": 240.519, "duration": 5.44}, {"text": "et avec des r\u00e9ponses de qualit\u00e9, r\u00e9dig\u00e9es\npar des humains. Et on n\u2019a pas vraiment", "start": 245.959, "duration": 3.992}, {"text": "ce genre de donn\u00e9es en quantit\u00e9 aujourd\u2019hui.", "start": 249.951, "duration": 2.279}, {"text": "Ensuite quand on imagine un \u00e9change avec\nun chatbot, il n\u2019y a jamais une bonne r\u00e9ponse", "start": 252.23, "duration": 4.58}, {"text": "unique qu\u2019on est en droit d\u2019attendre.\nPour la m\u00eame question, il peut y avoir des", "start": 256.81, "duration": 3.56}, {"text": "tas de r\u00e9ponses pertinentes plus ou moins\n\u00e9quivalentes, mais formul\u00e9es de fa\u00e7on potentiellement", "start": 260.37, "duration": 4.33}, {"text": "tr\u00e8s diff\u00e9rentes.", "start": 264.7, "duration": 1.0}, {"text": "Donc \u00e7a n\u2019est pas simple pour la phase\nd\u2019entrainement de faire comprendre au mod\u00e8le", "start": 265.7, "duration": 4.46}, {"text": "\u00e0 quel moment une r\u00e9ponse qu\u2019il propose\nest bonne, et \u00e0 quel moment c\u2019est \u00e0 c\u00f4t\u00e9", "start": 270.16, "duration": 4.13}, {"text": "de la plaque.", "start": 274.29, "duration": 1.0}, {"text": "Et enfin, dernier obstacle, si vous avez utilis\u00e9\nChatGPT vous avez remarqu\u00e9 que vous pouvez", "start": 275.29, "duration": 4.689}, {"text": "avoir toute une conversation avec. Il y a\nune notion de continuit\u00e9 dans l\u2019\u00e9change.", "start": 279.979, "duration": 4.281}, {"text": "Il utilise les questions et r\u00e9ponses pr\u00e9c\u00e9dentes\ndu dialogue pour poursuivre.", "start": 284.26, "duration": 3.58}, {"text": "Or si vous entrainez un mod\u00e8le simplement\nsur des couples de questions/r\u00e9ponses, chaque", "start": 287.84, "duration": 4.94}, {"text": "question sera trait\u00e9e ind\u00e9pendamment de\nce qui pourrait la pr\u00e9c\u00e9der dans l\u2019\u00e9change,", "start": 292.78, "duration": 3.8}, {"text": "et \u00e7a n\u2019est pas vraiment ce qu\u2019on veut.\nOn veut une continuit\u00e9 dans la conversation.", "start": 296.58, "duration": 4.95}, {"text": "Donc pour faire un chatbot efficace en utilisant\ndu machine learning, avoir une approche directe", "start": 301.53, "duration": 4.94}, {"text": "d\u2019apprentissage supervis\u00e9, \u00e7a ne semble\npas vraiment indiqu\u00e9. Et c\u2019est pour cela", "start": 306.47, "duration": 4.05}, {"text": "qu\u2019on va devoir proc\u00e9der en plusieurs \u00e9tapes,\nen utilisant comme base ce qu\u2019on appelle", "start": 310.52, "duration": 4.3}, {"text": "parfois un mod\u00e8le de fondation.", "start": 314.82, "duration": 2.32}, {"text": "Un mod\u00e8le de fondation, c\u2019est un mod\u00e8le\nd\u2019intelligence artificielle qui est entrain\u00e9", "start": 317.14, "duration": 4.33}, {"text": "sur une certaine t\u00e2che assez g\u00e9n\u00e9rique,\nmais dans le but d\u2019\u00eatre ensuite adapt\u00e9", "start": 321.47, "duration": 5.19}, {"text": "\u00e0 d\u2019autres t\u00e2ches plus sp\u00e9cifiques. Il\nexiste plusieurs mod\u00e8le de ce type dans le", "start": 326.66, "duration": 4.14}, {"text": "domaine du langage naturel, et celui qui va\nnous servir d\u2019exemple aujourd\u2019hui, c\u2019est", "start": 330.8, "duration": 3.839}, {"text": "donc le mod\u00e8le GPT cr\u00e9\u00e9 par l\u2019entreprise\nOpenAI.", "start": 334.639, "duration": 3.851}, {"text": "GPT, \u00e7a veut dire Generative Pretrained Transformer,\net c\u2019est un mod\u00e8le de manipulation du langage", "start": 338.49, "duration": 5.86}, {"text": "naturel qui est entrain\u00e9 sp\u00e9cifiquement\nsur une t\u00e2che qui peut paraitre un peu absurde", "start": 344.35, "duration": 4.75}, {"text": "au premier abord : ce mod\u00e8le cherche en permanence\n\u00e0 deviner le prochain mot d\u2019un texte.", "start": 349.1, "duration": 5.59}, {"text": "[GPT Ca veut dire qu\u2019il prend en entr\u00e9e\nun morceau de phrase ou de texte, ce qu\u2019on", "start": 354.69, "duration": 4.67}, {"text": "appelle le \u00ab\u00a0prompt\u00a0\u00bb, et il va essayer\nde produire en sortie un mot qui en soit une", "start": 359.36, "duration": 4.64}, {"text": "suite possible. Par exemple si on lui rentre\n\u00ab\u00a0La souris est mang\u00e9e par le\u00a0\u00bb, l\u2019algorithme", "start": 364.0, "duration": 5.139}, {"text": "est cens\u00e9 essayer de compl\u00e9ter le texte\nde fa\u00e7on cr\u00e9dible, par exemple ici avec", "start": 369.139, "duration": 4.28}, {"text": "le mot \u00ab\u00a0chat\u00a0\u00bb.", "start": 373.419, "duration": 1.331}, {"text": "Et \u00e7a doit marcher aussi avec un mot qui\nn\u2019est pas forc\u00e9ment le dernier de la phrase.", "start": 374.75, "duration": 3.509}, {"text": "Si je lui rentre juste \u00ab\u00a0la souris\u00a0\u00bb,\non peut imaginer comme suite possible le mot", "start": 378.259, "duration": 4.532}, {"text": "\u00ab\u00a0est\u00a0\u00bb, ou bien \u00ab\u00a0mange\u00a0\u00bb, ou encore\n\u00ab\u00a0verte\u00a0\u00bb, etc.", "start": 382.791, "duration": 3.658}, {"text": "En gros c\u2019est de la compl\u00e9tion automatique,\nmais qui doit fonctionner potentiellement", "start": 386.449, "duration": 4.62}, {"text": "\u00e0 l\u2019\u00e9chelle d\u2019un texte entier.]", "start": 391.069, "duration": 1.671}, {"text": "Pour que notre mod\u00e8le de langage soit bon\n\u00e0 ce petit jeu, il va falloir l\u2019entraider", "start": 392.74, "duration": 4.76}, {"text": "\u00e0 partir de donn\u00e9es existantes. C\u2019est-\u00e0-dire\nlui pr\u00e9senter des morceaux de phrases r\u00e9elles,", "start": 397.5, "duration": 4.72}, {"text": "et ajuster les param\u00e8tres du mod\u00e8le pour\nqu\u2019il soit de plus en plus performant \u00e0", "start": 402.22, "duration": 4.03}, {"text": "produire le mot suivant.", "start": 406.25, "duration": 1.42}, {"text": "Il y a plusieurs raisons pour lesquelles ce\nprincipe de \u00ab\u00a0deviner le prochain mot d\u2019un", "start": 407.67, "duration": 4.98}, {"text": "texte\u00a0\u00bb est une id\u00e9e bizarre mais int\u00e9ressante.\nTout d\u2019abord, \u00e7a n\u2019est pas une t\u00e2che", "start": 412.65, "duration": 4.079}, {"text": "qu\u2019on fait g\u00e9n\u00e9ralement en tant qu\u2019\u00eatre\nhumain.", "start": 416.729, "duration": 2.341}, {"text": "Quand on parle d\u2019algorithmes de reconnaissance\nd\u2019image ou de d\u00e9tection de fraude, on essaye", "start": 419.07, "duration": 4.83}, {"text": "de concevoir des mod\u00e8les d\u2019IA qui soient\ncapables d\u2019imiter et de d\u00e9passer les performances", "start": 423.9, "duration": 4.82}, {"text": "des humains sur ces t\u00e2ches. Ici deviner le\nprochain mot d\u2019un d\u00e9but de texte, personne", "start": 428.72, "duration": 5.01}, {"text": "ne fait \u00e7a dans la vraie vie, \u00e7a n\u2019a aucun\nint\u00e9r\u00eat pratique.", "start": 433.73, "duration": 3.219}, {"text": "Deuxi\u00e8me particularit\u00e9, on l\u2019a vu, dans\ncet exercice il n\u2019y a g\u00e9n\u00e9ralement pas", "start": 436.949, "duration": 3.781}, {"text": "*une* bonne r\u00e9ponse unique. Dans certains\ncas, il y a des r\u00e9ponses qui semblent plus", "start": 440.73, "duration": 5.029}, {"text": "naturelles, mais si je compl\u00e8te \u00ab la souris\nest mang\u00e9e par le\u00a0\u00bb avec le mot \u00ab corbeau\u00a0\u00bb,", "start": 445.759, "duration": 4.63}, {"text": "c\u2019est un peu inattendu mais c\u2019est pas\nsi mal. Pour compl\u00e9ter une phrase, on peut", "start": 450.389, "duration": 4.451}, {"text": "avoir en g\u00e9n\u00e9ral plein de r\u00e9ponses plus\nou moins plausibles.", "start": 454.84, "duration": 3.02}, {"text": "Et il faut bien comprendre ce que veut dire\n\u00ab\u00a0plausible\u00a0\u00bb ici : \u00e7a ne veut pas dire", "start": 457.86, "duration": 3.55}, {"text": "que c\u2019est vrai, il n\u2019y a aucune notion\nde v\u00e9rit\u00e9 dans la fa\u00e7on dont le mod\u00e8le", "start": 461.41, "duration": 3.561}, {"text": "est entrain\u00e9. Si je dis \u00ab\u00a0La souris est\nmang\u00e9e par le\u00a0\u00bb, il n\u2019y a pas de vraie", "start": 464.971, "duration": 4.679}, {"text": "r\u00e9ponse universelle \u00e0 la question de ce\nqui vient derri\u00e8re.", "start": 469.65, "duration": 2.78}, {"text": "Plausible \u00e7a veut dire que cette fa\u00e7on de\ncompl\u00e9ter la phrase ressemble \u00e0 ce qu\u2019on", "start": 472.43, "duration": 5.64}, {"text": "trouverait dans les textes qui ont servi \u00e0\nentrainer le mod\u00e8le. \u00ab\u00a0Chat\u00a0\u00bb est tr\u00e8s", "start": 478.07, "duration": 3.87}, {"text": "naturel, mais \u00ab\u00a0corbeau\u00a0\u00bb, pourquoi pas.", "start": 481.94, "duration": 2.19}, {"text": "Et attention, si un mod\u00e8le r\u00e9pond \u00ab\u00a0Corbeau\u00a0\u00bb\npour compl\u00e9ter cette phrase, \u00e7a ne veut", "start": 484.13, "duration": 4.58}, {"text": "pas forc\u00e9ment dire que quelque part dans\nles textes de son entrainement on trouve \u00ab\u00a0la", "start": 488.71, "duration": 4.41}, {"text": "souris est mang\u00e9e par le corbeau\u00a0\u00bb. Non,\nil ne se contente pas de r\u00e9p\u00e9ter des phrases", "start": 493.12, "duration": 3.26}, {"text": "existantes.", "start": 496.38, "duration": 1.0}, {"text": "D\u2019ailleurs j\u2019ai regard\u00e9, nulle part sur\ninternet on ne trouve cette phrase exacte.", "start": 497.38, "duration": 3.92}, {"text": "Il n\u2019emp\u00eache que si je vous dit \u00ab\u00a0la\nsouris est mang\u00e9e par le corbeau\u00a0\u00bb, \u00e7a", "start": 501.3, "duration": 3.69}, {"text": "ne vous choque pas. Si on pense aux mots \u00ab\u00a0corbeau\u00a0\u00bb,\n\u00ab\u00a0manger\u00a0\u00bb, et \u00ab\u00a0souris\u00a0\u00bb : le sens", "start": 504.99, "duration": 4.07}, {"text": "et les relations de ces diff\u00e9rents termes\nfont que cette fa\u00e7on de compl\u00e9ter est raisonnable.", "start": 509.06, "duration": 5.339}, {"text": "Ca ressemble \u00e0 ce qu\u2019on aurait pu trouver\ndans les textes d\u2019entrainement.", "start": 514.399, "duration": 3.171}, {"text": "Une fa\u00e7on que j\u2019aime bien de le pr\u00e9senter,\nc\u2019est de dire qu\u2019un mod\u00e8le comme GPT", "start": 517.57, "duration": 4.81}, {"text": "va chercher une fa\u00e7on de compl\u00e9ter qui soit\nressemble \u00e0 des choses existantes, soit du", "start": 522.38, "duration": 4.98}, {"text": "moins ne d\u00e9pareillerai pas trop avec les\ntextes existants. Si demain je lis sur un", "start": 527.36, "duration": 4.539}, {"text": "site internet \u00ab\u00a0La souris est mang\u00e9e par\nle corbeau\u00a0\u00bb, \u00e7a n\u2019aura rien d\u2019incongru.", "start": 531.899, "duration": 3.701}, {"text": "Ca ne d\u00e9pareillerai pas.", "start": 535.6, "duration": 1.72}, {"text": "Donc je r\u00e9sume : pour compl\u00e9ter, le mod\u00e8le\nne cherche pas \u00e0 dire quelque chose de vrai,", "start": 537.32, "duration": 4.72}, {"text": "il ne sait m\u00eame pas ce que sait que la v\u00e9rit\u00e9;\nle mod\u00e8le ne cherche pas forc\u00e9ment \u00e0 reproduire", "start": 542.04, "duration": 3.76}, {"text": "exactement un texte existant, mais il fabrique\nune phrase plausible, qui ne d\u00e9pareillerait", "start": 545.8, "duration": 5.87}, {"text": "pas trop au milieu de tout ce qu\u2019il a pu\ningurgiter durant son entrainement.", "start": 551.67, "duration": 4.08}, {"text": "Evidemment cette m\u00e9thode qui consiste \u00e0\nessayer d\u2019ajouter un mot de plus \u00e0 un texte,", "start": 555.75, "duration": 4.37}, {"text": "\u00e7a a un gros avantage : on peut r\u00e9p\u00e9ter\n\u00e7a plusieurs fois de suite. Et donc \u00e0 partir", "start": 560.12, "duration": 4.2}, {"text": "d\u2019un simple d\u00e9but de phrase, on peut demander\nau mod\u00e8le de continuer \u00e0 ajouter des mots,", "start": 564.32, "duration": 4.769}, {"text": "un par un, jusqu\u2019\u00e0 former un texte aussi\ngrand qu\u2019on veut.", "start": 569.089, "duration": 3.81}, {"text": "[TEXTELONG Ici si je lui dis \u00ab\u00a0La souris\nest mang\u00e9e par le\u00a0\u00bb et que je lui demande", "start": 572.899, "duration": 3.891}, {"text": "de prolonger le texte suffisamment, voici\nle genre de r\u00e9sultat que j\u2019obtiens. C\u2019est", "start": 576.79, "duration": 4.78}, {"text": "plausible, \u00e7a sonne bien fran\u00e7ais, \u00e7a a\ndu sens.]", "start": 581.57, "duration": 2.74}, {"text": "Bien, voyons plus pr\u00e9cis\u00e9ment maintenant\ncomment on proc\u00e8de en pratique pour cr\u00e9er", "start": 584.31, "duration": 4.1}, {"text": "un mod\u00e8le comme GPT. Premi\u00e8re pr\u00e9cision\nun peu technique, les mod\u00e8les de langage", "start": 588.41, "duration": 4.68}, {"text": "travaillent en g\u00e9n\u00e9ral non pas au niveau\ndes mots, mais au niveau de ce qu\u2019on appelle", "start": 593.09, "duration": 3.52}, {"text": "des tokens.", "start": 596.61, "duration": 1.0}, {"text": "Un token, c\u2019est en gros soit un mot, soit\nune portion de mot. Les mots les plus longs", "start": 597.61, "duration": 5.45}, {"text": "peuvent \u00eatre faits de deux ou trois tokens.\nEn pratique \u00e7a ne change pas grand chose,", "start": 603.06, "duration": 4.34}, {"text": "mais \u00e7a peut expliquer pourquoi un mod\u00e8le\ncomme GPT va parfois pr\u00e9dire certains mots", "start": 607.4, "duration": 3.86}, {"text": "en plusieurs morceaux successifs.", "start": 611.26, "duration": 1.41}, {"text": "Ce que j\u2019ai utilis\u00e9 jusqu\u2019ici, c\u2019est\nla troisi\u00e8me it\u00e9ration de GPT, qu\u2019on appelle", "start": 612.67, "duration": 4.68}, {"text": "GPT3, qui est sorti en juillet 2020. Il a\nconnu une am\u00e9lioration en GPT3.5 en mars", "start": 617.35, "duration": 6.58}, {"text": "2022, et depuis mars 2023, on peut m\u00eame avoir\nacc\u00e8s \u00e0 GPT4, dont on ne sait malheureusement", "start": 623.93, "duration": 5.599}, {"text": "pas grand chose.", "start": 629.529, "duration": 1.631}, {"text": "GPT3 poss\u00e8de un vocabulaire d\u2019environ 50\n000 tokens, et qui n\u2019est pas sp\u00e9cifique", "start": 631.16, "duration": 4.74}, {"text": "d\u2019une langue en particulier. Ces tokens\npermettent de former des mots anglais, fran\u00e7ais,", "start": 635.9, "duration": 4.32}, {"text": "espagnols, etc. Pour faire simple dans la\nsuite, je vais parler indiff\u00e9remment de \u00ab\u00a0mot\u00a0\u00bb", "start": 640.22, "duration": 4.53}, {"text": "ou de \u00ab\u00a0token\u00a0\u00bb, \u00e7a revient presque au\nm\u00eame pour nous.", "start": 644.75, "duration": 2.93}, {"text": "Ensuite, comment se passe la phase d\u2019entrainement\ndu mod\u00e8le ? Je vous ai dit que dans des t\u00e2ches", "start": 647.68, "duration": 4.159}, {"text": "d\u2019apprentissage supervis\u00e9, comme la reconnaissance\nd\u2019images, il fallait disposer de grandes", "start": 651.839, "duration": 3.871}, {"text": "bases de donn\u00e9es, qui illustrent sur de nombreux\nexemples la r\u00e9ponse qu\u2019on attendrait.", "start": 655.71, "duration": 4.45}, {"text": "[ANNOTATION L\u2019inconv\u00e9nient, c\u2019est que\nces bases de donn\u00e9es doivent \u00eatre fabriqu\u00e9es", "start": 660.16, "duration": 3.75}, {"text": "en quelque sorte \u00e0 la main, puisqu\u2019\u00e0 un\nmoment donn\u00e9, c\u2019est g\u00e9n\u00e9ralement un humain", "start": 663.91, "duration": 4.29}, {"text": "qui doit indiquer que ceci est un chat et\nceci une voiture. On dit qu\u2019il faut annoter", "start": 668.2, "duration": 4.72}, {"text": "la base de donn\u00e9es. Et c\u2019est souvent ce\nprocessus d\u2019annotation qui limite la quantit\u00e9", "start": 672.92, "duration": 4.38}, {"text": "des donn\u00e9es disponibles.]", "start": 677.3, "duration": 1.0}, {"text": "[SELF SUPERVISED Dans le cas de la pr\u00e9diction\ndu prochain mot d\u2019un texte, c\u2019est tr\u00e8s", "start": 678.3, "duration": 4.06}, {"text": "simple. Il suffit de prendre par exemple une\nphrase prise dans un livre ou sur un site", "start": 682.36, "duration": 4.219}, {"text": "internet, de la couper n\u2019importe o\u00f9 et\nde fournir \u00e7a au mod\u00e8le pour qu\u2019il s\u2019entraine", "start": 686.579, "duration": 4.241}, {"text": "\u00e0 deviner le prochain mot. Avec une seule\nphrase, on peut m\u00eame cr\u00e9er tout plein d\u2019exemples", "start": 690.82, "duration": 4.079}, {"text": "en la coupant \u00e0 diff\u00e9rents endroits.]", "start": 694.899, "duration": 1.44}, {"text": "Il n\u2019y a donc pas besoin d\u2019un processus\nd\u2019annotation sp\u00e9cifique, o\u00f9 un humain", "start": 696.339, "duration": 5.12}, {"text": "devrait faire une partie du travail. On peut\nprendre des tonnes de textes et g\u00e9n\u00e9rer", "start": 701.459, "duration": 4.051}, {"text": "des milliards d\u2019exemples pour entrainer\nle mod\u00e8le. On parle parfois d\u2019apprentissage", "start": 705.51, "duration": 4.86}, {"text": "auto-supervis\u00e9, self-supervised learning\nen anglais. Dans le cas du mod\u00e8le GPT3 d\u2019OpenAI,", "start": 710.37, "duration": 5.23}, {"text": "on a certaines indications quant au corpus\nde texte qui a \u00e9t\u00e9 utilis\u00e9 pour entrainer", "start": 715.6, "duration": 4.87}, {"text": "le mod\u00e8le.", "start": 720.47, "duration": 1.0}, {"text": "[CORPUS Il y a du texte de Common Crawl, donc\nsimplement ramass\u00e9 sur internet, des bases", "start": 721.47, "duration": 4.45}, {"text": "de donn\u00e9es de livres, et aussi tout Wikipedia\nen anglais. Sachant que certaines de ces sources", "start": 725.92, "duration": 5.349}, {"text": "ont eu plus de poids que d\u2019autres dans la\nphase d\u2019entrainement. On peut esp\u00e9rer que", "start": 731.269, "duration": 3.361}, {"text": "Wikip\u00e9dia p\u00e8se un peu plus dans son apprentissage\nque Reddit ou 4chan.", "start": 734.63, "duration": 4.42}, {"text": "Et m\u00eame si on trouve plein de langues diff\u00e9rentes\ndans les textes du corpus d\u2019entrainement,", "start": 739.05, "duration": 4.22}, {"text": "une moiti\u00e9 environ c\u2019est de l\u2019anglais,\nsans surprise.]", "start": 743.27, "duration": 2.879}, {"text": "Un point important, c\u2019est que dans un fonctionnement\nclassique, l\u2019entrainement a lieu une fois,", "start": 746.149, "duration": 5.091}, {"text": "et ensuite le mod\u00e8le est fig\u00e9. C\u2019est la\nraison pour laquelle les connaissances de", "start": 751.24, "duration": 3.62}, {"text": "GPT sont en g\u00e9n\u00e9ral limit\u00e9e \u00e0 une certaine\ndate, il ne connait pas les \u00e9v\u00e9nements r\u00e9cents.", "start": 754.86, "duration": 4.31}, {"text": "Et aussi cela explique que d\u2019une conversation\n\u00e0 l\u2019autre, il n\u2019a aucune m\u00e9moire de", "start": 759.17, "duration": 4.229}, {"text": "ce que vous avez pu d\u00e9j\u00e0 discuter. Ces deux\nlimitations disparaitront peut-\u00eatre \u00e0 l\u2019avenir,", "start": 763.399, "duration": 5.611}, {"text": "mais dans le mod\u00e8le de base, c\u2019est comme\n\u00e7a que \u00e7a se passe. C\u2019est un mod\u00e8le fig\u00e9.", "start": 769.01, "duration": 3.02}, {"text": "Je ne vais pas rentrer dans les d\u00e9tails techniques\nde fonctionnement du mod\u00e8le, et des r\u00e9seaux", "start": 772.03, "duration": 4.48}, {"text": "de neurones qu\u2019il y a derri\u00e8re. J\u2019en\nai d\u00e9j\u00e0 parl\u00e9 dans ma vid\u00e9o pr\u00e9c\u00e9dente", "start": 776.51, "duration": 3.08}, {"text": "sur le sujet, mais il y a quelques points\nqui sont int\u00e9ressants \u00e0 mentionner.", "start": 779.59, "duration": 3.82}, {"text": "Sur la taille d\u00e9j\u00e0, GPT3 est un mod\u00e8le\nqui poss\u00e8de 175 milliards de param\u00e8tres,", "start": 783.41, "duration": 5.6}, {"text": "ce qui est assez invraisemblable. Pour GPT4\non ne sait pas vraiment. Peut \u00eatre 6 \u00e0 10", "start": 789.01, "duration": 4.18}, {"text": "fois plus.", "start": 793.19, "duration": 1.0}, {"text": "Ensuite que donne-t-on exactement au mod\u00e8le\nlors de la phase d\u2019entrainement ? Je l\u2019ai", "start": 794.19, "duration": 3.889}, {"text": "\u00e9voqu\u00e9, GPT ne va pas s\u2019entrainer \u00e0 trouver\nle prochain mot d\u2019une simple phrase, mais", "start": 798.079, "duration": 3.671}, {"text": "potentiellement d\u2019un texte tout entier,\nconstitu\u00e9 \u00e9ventuellement de plusieurs phrases.", "start": 801.75, "duration": 3.7}, {"text": "Ce qui permet d\u2019assurer une forme de continuit\u00e9\net de m\u00e9moire de l\u2019\u00e9change.", "start": 805.45, "duration": 4.48}, {"text": "La taille maximum de texte qu\u2019il prend en\ncompte pour estimer le prochain mot, on appelle", "start": 809.93, "duration": 4.82}, {"text": "cela la fen\u00eatre de contexte. Cette taille\nd\u00e9pend de la version de l\u2019algorithme. Dans", "start": 814.75, "duration": 5.339}, {"text": "GPT3 c\u2019\u00e9tait 2048 tokens, puis c\u2019est\npass\u00e9 \u00e0 4096 pour la version 3.5 et apparemment", "start": 820.089, "duration": 5.671}, {"text": "jusqu\u2019\u00e0 plus de 32000 pour la version 4.", "start": 825.76, "duration": 2.43}, {"text": "Ca veut dire, pour la version la plus puissante,\nqu\u2019on peut lui filer un texte d\u2019environ", "start": 828.19, "duration": 3.95}, {"text": "25000 mots, et que tous ces mots pourront\npotentiellement \u00eatre pris en compte pour", "start": 832.14, "duration": 4.58}, {"text": "d\u00e9cider du simple mot suivant. Une autre\nfa\u00e7on de le dire : GPT4 peut, si besoin,", "start": 836.72, "duration": 5.01}, {"text": "se rappeler d\u2019une information qui \u00e9tait\nsitu\u00e9 25 000 mots plus t\u00f4t dans le texte.", "start": 841.73, "duration": 4.19}, {"text": "Ce qui fait une centaine de page en format\nstandard.", "start": 845.92, "duration": 2.26}, {"text": "Parlons maintenant de ce qui est donn\u00e9 en\nsortie par l\u2019algorithme. On l\u2019a dit, quand", "start": 848.18, "duration": 3.87}, {"text": "on cherche \u00e0 trouver le prochain mot d\u2019une\nphrase ou d\u2019un texte, il n\u2019y a g\u00e9n\u00e9ralement", "start": 852.05, "duration": 3.89}, {"text": "pas une seule r\u00e9ponse possible. Et justement,\nle mod\u00e8le ne va pas nous fournir un seul", "start": 855.94, "duration": 4.62}, {"text": "mot, mais une liste de mots envisageables\navec des probabilit\u00e9s associ\u00e9es.", "start": 860.56, "duration": 4.42}, {"text": "[PROBAS Par exemple \u00ab\u00a0Chat\u00a0\u00bb \u00e0 90%, \u00ab\u00a0Chien\u00a0\u00bb\n\u00e0 7%, \u00ab\u00a0Corbeau\u00a0\u00bb \u00e0 1%, etc. Et \u00e0 partir", "start": 864.98, "duration": 6.79}, {"text": "de ces estimations, on peut demander ensuite\n\u00e0 tirer au hasard le mot suivant parmi cette", "start": 871.77, "duration": 5.569}, {"text": "liste, en suivant les probabilit\u00e9s fournies.]", "start": 877.339, "duration": 2.291}, {"text": "[PROBAS Sur le site d\u2019OpenAI, on peut acc\u00e9der\n\u00e0 GPT3 en mode dit \u00ab\u00a0Playground\u00a0\u00bb, c\u2019est", "start": 879.63, "duration": 4.59}, {"text": "l\u00e0 que j\u2019ai test\u00e9 les exemples que je\nvous ai montr\u00e9. Quand on lui demande de compl\u00e9ter,", "start": 884.22, "duration": 4.58}, {"text": "le mod\u00e8le va tout de suite nous tirer au\nhasard le prochain mot parmi ses r\u00e9ponses", "start": 888.8, "duration": 3.49}, {"text": "possibles, mais en cochant une option dans\nl\u2019interface, on peut visualiser les probabilit\u00e9s", "start": 892.29, "duration": 4.65}, {"text": "qu\u2019il avait propos\u00e9.]", "start": 896.94, "duration": 1.089}, {"text": "Alors allons-y, faisons quelques exp\u00e9riences\npour bien comprendre ce qu\u2019il se passe,", "start": 898.029, "duration": 3.75}, {"text": "je vais les faire en anglais puisque c\u2019est\nla langue \u00e0 laquelle GPT3 a \u00e9t\u00e9 le plus", "start": 901.779, "duration": 3.25}, {"text": "expos\u00e9. Ce sera certainement un peu meilleur.", "start": 905.029, "duration": 2.3}, {"text": "[COLOMB Si j\u2019\u00e9cris la phrase : \u00ab\u00a0Christophe\nColomb a d\u00e9couvert l\u2019Am\u00e9rique en\u00a0\u00bb il", "start": 907.329, "duration": 5.682}, {"text": "me propose comme compl\u00e9tion : 1492. Super,\non s\u2019y attendait. Mais il faut bien comprendre", "start": 913.011, "duration": 6.209}, {"text": "pourquoi le mod\u00e8le de langage nous donne\ncette r\u00e9ponse : \u00e7a n\u2019est pas qu\u2019il a", "start": 919.22, "duration": 3.739}, {"text": "un concept de de v\u00e9rit\u00e9 sur cette question.\nPour lui c\u2019est m\u00eame pas une question.", "start": 922.959, "duration": 3.641}, {"text": "C\u2019est juste que dans les textes qui ont\nservi \u00e0 son entrainement, les mots \u00ab\u00a0Christophe", "start": 926.6, "duration": 4.299}, {"text": "Colomb\u00a0\u00bb, \u00ab\u00a0d\u00e9couverte\u00a0\u00bb \u00ab\u00a0am\u00e9rique\u00a0\u00bb\nsont en g\u00e9n\u00e9ral toujours tr\u00e8s fortement", "start": 930.899, "duration": 3.67}, {"text": "associ\u00e9s au mot 1492. Et donc pour lui, 1492\nest de loin la suite la plus naturelle \u00e0", "start": 934.569, "duration": 6.51}, {"text": "ce d\u00e9but de phrase.]", "start": 941.079, "duration": 1.021}, {"text": "[PROBAS (On peut observer les probabilit\u00e9s\ndes diff\u00e9rents mots que GPT a consid\u00e9r\u00e9", "start": 942.1, "duration": 3.669}, {"text": ": on voit qu\u2019on y trouve aussi \u00ab\u00a0Octobre\u00a0\u00bb\ndans les suite possibles pour cette phrase.", "start": 945.769, "duration": 4.421}, {"text": "C\u2019est coh\u00e9rent, Colomb a touch\u00e9 les c\u00f4tes\ndes Bahamas le 12 octobre 1492.]", "start": 950.19, "duration": 3.79}, {"text": "Mais attention, je le rappelle, quand on utilise\nGPT pour compl\u00e9ter une phrase, on ne va pas", "start": 953.98, "duration": 5.74}, {"text": "forc\u00e9ment produire des choses \u00ab\u00a0vraies\u00a0\u00bb.", "start": 959.72, "duration": 1.35}, {"text": "[DL1492 Par exemple si je tape \u00ab\u00a0David Louapre\na d\u00e9couvert l\u2019Am\u00e9rique en\u00a0\u00bb, \u00e7a n\u2019a", "start": 961.07, "duration": 6.78}, {"text": "aucun lien avec la r\u00e9alit\u00e9. Mais GPT s\u2019en\nmoque, il ne va pas refuser de r\u00e9pondre sous", "start": 967.85, "duration": 4.729}, {"text": "pr\u00e9texte que c\u2019est faux. Il fait donc la\nseule chose qu\u2019il sache faire : il propose", "start": 972.579, "duration": 3.791}, {"text": "un mot pour compl\u00e9ter la phrase.", "start": 976.37, "duration": 1.519}, {"text": "Et l\u00e0 il me propose aussi 1492. M\u00eame si\non voit dans les probabilit\u00e9s qu\u2019il aurait", "start": 977.889, "duration": 5.132}, {"text": "pu proposer d\u2019autres choses.", "start": 983.021, "duration": 1.909}, {"text": "Comme toujours, il essaye de g\u00e9n\u00e9rer le\nprochain mot d\u2019une fa\u00e7on qui colle le plus", "start": 984.93, "duration": 4.68}, {"text": "avec son corpus d\u2019entrainement, ou ici,\nd\u2019une fa\u00e7on qui d\u00e9pareille le moins possible.", "start": 989.61, "duration": 4.52}, {"text": "M\u00eame si \u00ab\u00a0David Louapre\u00a0\u00bb \u00e7a ne colle\npas, les mots \u00ab\u00a0am\u00e9rique\u00a0\u00bb \u00ab\u00a0d\u00e9couverte\u00a0\u00bb,", "start": 994.13, "duration": 3.78}, {"text": "il associe cela toujours fortement \u00e0 1492.]", "start": 997.91, "duration": 2.75}, {"text": "Un autre test pour bien illustrer ce qu\u2019il\nse passe dans la t\u00eate de GPT.", "start": 1000.66, "duration": 3.83}, {"text": "[BOND Si je tape comme prompt \u00ab\u00a0Dans le\nfilm de James Bond \u00ab\u00a0La trahison ne se cache", "start": 1004.49, "duration": 5.899}, {"text": "jamais\u00a0\u00bb, l\u2019acteur qui joue James Bond\ns\u2019appelle\u00a0\u00bb \u2026 et l\u00e0 vous voyez qu\u2019il", "start": 1010.389, "duration": 3.64}, {"text": "n\u2019y a pas de notion de vrai ou faux, le\nfilm n\u2019existe m\u00eame pas, c\u2019est un titre", "start": 1014.029, "duration": 3.401}, {"text": "invent\u00e9.", "start": 1017.43, "duration": 1.0}, {"text": "Mais GPT cherche des compl\u00e9tions plausibles,\nqui ne d\u00e9pareillent pas trop. Il me propose", "start": 1018.43, "duration": 4.68}, {"text": "naturellement \u00ab\u00a0Daniel Craig\u00a0\u00bb, mais si\non regarde les probabilit\u00e9s, on voit qu\u2019il", "start": 1023.11, "duration": 4.9}, {"text": "consid\u00e9rait aussi en bonne position \u00ab\u00a0Pierce\u00a0\u00bb,\npour Pierce Brosnan, Sean pour Sean Connery,", "start": 1028.01, "duration": 4.74}, {"text": "etc.", "start": 1032.75, "duration": 1.0}, {"text": "Ce sont toutes des compl\u00e9tions raisonnables.\nM\u00eame si ce film n\u2019existe pas, une telle", "start": 1033.75, "duration": 3.66}, {"text": "phrase n\u2019aurait pas trop d\u00e9pareill\u00e9 dans\nle corpus initial.", "start": 1037.41, "duration": 4.81}, {"text": "Petite variation : si je pr\u00e9cise que le film\nest vieux, les probabilit\u00e9s changent. Eh", "start": 1042.22, "duration": 4.92}, {"text": "bien oui, cette pr\u00e9cision augmente la probabilit\u00e9\nqu\u2019il propose un des premiers acteurs qui", "start": 1047.14, "duration": 4.27}, {"text": "ont jou\u00e9 James Bond comme Sean Connery ou\nRoger Moore.]", "start": 1051.41, "duration": 2.769}, {"text": "Donc retenez \u00e7a : GPT cherche le prochain\nmot d\u2019une fa\u00e7on qui soit raisonnable, qui", "start": 1054.179, "duration": 4.261}, {"text": "ne d\u00e9pareille pas trop vis-\u00e0-vis de son\ncorpus. Et \u00ab\u00a0raisonnable\u00a0\u00bb, \u00ab\u00a0plausible\u00a0\u00bb,", "start": 1058.44, "duration": 4.29}, {"text": "c\u2019est \u00e0 prendre en compte non pas dans\nle sens de \u00ab\u00a0proche de la v\u00e9rit\u00e9\u00a0\u00bb,", "start": 1062.73, "duration": 4.11}, {"text": "mais dans le sens de : \u00e7a n\u2019aurait pas\n\u00e9t\u00e9 absurde de lire ces mots l\u00e0 associ\u00e9s", "start": 1066.84, "duration": 4.199}, {"text": "ensembles de cette fa\u00e7on dans le corpus d\u2019entrainement.", "start": 1071.039, "duration": 2.311}, {"text": "Et on peut lui faire \u00e9crire des paragraphes\nentiers de choses qui n\u2019existent pas.", "start": 1073.35, "duration": 3.01}, {"text": "[LICORNES Ici si je commence \u00e0 lui parler\nde licornes argent\u00e9es, et que je lui demande", "start": 1076.36, "duration": 4.87}, {"text": "de compl\u00e9ter plein de fois de suite, il m\u2019invente\ntout un texte. Et le texte est pas mal, \u00e0", "start": 1081.23, "duration": 5.14}, {"text": "part pour les licornes elles-m\u00eames, \u00e7a pourrait\ntout \u00e0 fait \u00eatre issu d\u2019un article de", "start": 1086.37, "duration": 3.59}, {"text": "journal.]", "start": 1089.96, "duration": 1.0}, {"text": "Et pour finir, si je tape un peu n\u2019importe\nquoi, GPT va quand m\u00eame essayer de compl\u00e9ter", "start": 1090.96, "duration": 5.15}, {"text": "ce texte de la fa\u00e7on la moins improbable\npour lui. Bon je pense que vous avez compris", "start": 1096.11, "duration": 4.95}, {"text": "comment \u00e7a fonctionne.", "start": 1101.06, "duration": 1.11}, {"text": "Bien alors est-ce qu\u2019on peut faire un chatbot\navec ce genre de choses ? Eh bien pas tout", "start": 1102.17, "duration": 5.181}, {"text": "\u00e0 fait. Evidemment, on peut essayer de taper\ndes questions en guise de prompt, et esp\u00e9rer", "start": 1107.351, "duration": 5.299}, {"text": "une r\u00e9ponse en retour. Mais en fait, \u00e7a\nn\u2019est m\u00eame pas garanti.", "start": 1112.65, "duration": 3.55}, {"text": "GPT ne consid\u00e8re pas qu\u2019on s\u2019adresse\n\u00e0 lui et qu\u2019on lui pose une question, il", "start": 1116.2, "duration": 5.101}, {"text": "consid\u00e8re qu\u2019il faut compl\u00e9ter le texte.\nUn texte qui commence par une question, \u00e7a", "start": 1121.301, "duration": 3.849}, {"text": "peut se poursuivre par une r\u00e9ponse, mais\npas forc\u00e9ment.", "start": 1125.15, "duration": 3.33}, {"text": "[LUNE Si je tape : \u00ab\u00a0Quelle est la masse\nde la Lune\u00a0\u00bb, il est tout \u00e0 fait possible", "start": 1128.48, "duration": 3.51}, {"text": "qu\u2019il compl\u00e8te avec une r\u00e9ponse cens\u00e9e,\nmais il peut aussi tr\u00e8s bien compl\u00e9ter\u00a0par", "start": 1131.99, "duration": 4.12}, {"text": "\u00ab\u00a0Quelles sont les lois de la gravitation\u00a0?\u00a0\u00bb\n\u00ab\u00a0Qu\u2019est-ce que la rotation de la lune", "start": 1136.11, "duration": 3.16}, {"text": "?\u00a0\u00bb etc.", "start": 1139.27, "duration": 1.0}, {"text": "Eh oui, la phrase \u00ab\u00a0quelle est la masse\nde la Lune\u00a0\u00bb peut tr\u00e8s bien se trouver", "start": 1140.27, "duration": 4.31}, {"text": "dans un exercice ou un sujet d\u2019examen, et\ndonc compl\u00e9ter une question par une autre", "start": 1144.58, "duration": 5.04}, {"text": "question, \u00e7a n\u2019est pas absurde. C\u2019est\nune compl\u00e9tion plausible.]", "start": 1149.62, "duration": 4.189}, {"text": "On voit avec \u00e7a que comme GPT n\u2019est pas\nentrain\u00e9 \u00e0 suivre des instructions mais", "start": 1153.809, "duration": 4.021}, {"text": "\u00e0 juste compl\u00e9ter un texte, il n\u2019est pas\ncompl\u00e8tement adapt\u00e9 pour faire un chatbot.", "start": 1157.83, "duration": 4.51}, {"text": "Une possibilit\u00e9 pour l\u2019emmener dans la\ndirection o\u00f9 on veut, c\u2019est de faire ce", "start": 1162.34, "duration": 3.579}, {"text": "qu\u2019on appelle un preprompt.", "start": 1165.919, "duration": 1.26}, {"text": "Avant votre prompt, qui est votre question,\nvous \u00e9crivez une intro qui va en quelque", "start": 1167.179, "duration": 5.531}, {"text": "sorte mettre GPT dans l\u2019ambiance du genre\nde texte qu\u2019on veut le voir r\u00e9diger.", "start": 1172.71, "duration": 4.51}, {"text": "[PREPROMPT Par exemple, \u00ab\u00a0Ceci est une conversation\nentre un humain et un professeur de physique\u00a0\u00bb", "start": 1177.22, "duration": 5.549}, {"text": ": - Quelle est la masse de la Lune ?\u00a0\u00bb Et\nl\u00e0 il y a des chances que GPT soit plus enclin", "start": 1182.769, "duration": 4.451}, {"text": "\u00e0 compl\u00e9ter selon ce qu\u2019on d\u00e9sire. Comme\ns\u2019il s\u2019agissait vraiment d\u2019une discussion", "start": 1187.22, "duration": 4.391}, {"text": "avec un prof de physique.]", "start": 1191.611, "duration": 1.308}, {"text": "Avec la m\u00e9thode du preprompt, on peut en\nquelque sorte invoquer des personnes avec", "start": 1192.919, "duration": 4.351}, {"text": "qui on va pouvoir dialoguer. En faisant un\npreprompt qui invite un sp\u00e9cialiste de tel", "start": 1197.27, "duration": 4.409}, {"text": "ou tel sujet, on augmente les chances que\nGPT nous compl\u00e8te notre phrase avec quelque", "start": 1201.679, "duration": 4.301}, {"text": "chose de pertinent.", "start": 1205.98, "duration": 1.0}, {"text": "Cette id\u00e9e du preprompt est \u00e9galement \u00e0\nla base de certaines applications comme Replika", "start": 1206.98, "duration": 4.64}, {"text": "qui vous proposent de parler avec un ou une\namie virtuelle. Avec un bon pre-prompt l\u2019\u00e9change", "start": 1211.62, "duration": 5.559}, {"text": "produit pourra plus ou moins ressembler \u00e0\ncelui qu\u2019on aurait avec quelqu\u2019un de r\u00e9el.", "start": 1217.179, "duration": 3.581}, {"text": "Donc si maintenant on veut que GPT se comporte\ncomme un chatbot omniscient et sympathique,", "start": 1220.76, "duration": 4.73}, {"text": "il suffit de lui indiquer dans le preprompt.\nUn truc du genre \u00ab\u00a0Ceci est une conversation", "start": 1225.49, "duration": 5.2}, {"text": "entre un humain et un chatbot tr\u00e8s savant,\net qui est toujours gentil, utile, poli, bienveillant", "start": 1230.69, "duration": 4.79}, {"text": "et aidant\u00a0\u00bb.", "start": 1235.48, "duration": 1.0}, {"text": "[SYDNEY On ne connait pas exactement le preprompt\nutilis\u00e9 par ChatGPT, c\u2019est secret, et manifestement", "start": 1236.48, "duration": 5.439}, {"text": "il \u00e9volue. Mais certains auraient r\u00e9ussi\n\u00e0 obtenir celui de Sydney, la variante utilis\u00e9e", "start": 1241.919, "duration": 5.431}, {"text": "par le moteur Bing.", "start": 1247.35, "duration": 1.14}, {"text": "Voici ce que ce serait, c\u2019est assez long\nvous voyez, et \u00e7a contient plein d\u2019instructions", "start": 1248.49, "duration": 4.74}, {"text": "assez pr\u00e9cises sur sa fa\u00e7on de r\u00e9pondre,\net notamment le fait de ne pas r\u00e9v\u00e9ler qu\u2019il", "start": 1253.23, "duration": 4.8}, {"text": "s\u2019appelle Sydney.]", "start": 1258.03, "duration": 1.0}, {"text": "Mais attention, utiliser un pre-prompt, \u00e7a\nne fait pas tout. Pour bien vous montrer les", "start": 1259.03, "duration": 4.57}, {"text": "limites, il y a un point amusant.", "start": 1263.6, "duration": 1.11}, {"text": "[COMPLETION DIALOGUE Si vous posez une question\ndont la r\u00e9ponse est courte et que vous demandez", "start": 1264.71, "duration": 3.57}, {"text": "\u00e0 GPT de compl\u00e9ter, parfois il va non seulement\ndonner la r\u00e9ponse, mais \u00e9crire la question", "start": 1268.28, "duration": 5.259}, {"text": "suivante, voire carr\u00e9ment toute la suite\ndu dialogue.", "start": 1273.539, "duration": 2.74}, {"text": "Ou bien des fois il va choisir de compl\u00e9ter\nla question par un truc que je n\u2019ai pas", "start": 1276.279, "duration": 5.081}, {"text": "demand\u00e9.]", "start": 1281.36, "duration": 1.0}, {"text": "Une derni\u00e8re fois pour la route : GPT n\u2019est\npas entrain\u00e9 \u00e0 r\u00e9pondre \u00e0 des questions", "start": 1282.36, "duration": 2.63}, {"text": "ou \u00e0 suivre des instructions, mais \u00e0 prolonger\ndes textes. Pour essayer de corriger un peu", "start": 1284.99, "duration": 4.71}, {"text": "cela dans le mod\u00e8le, il existe une m\u00e9thode\n: ce qu\u2019on appelle le fine-tuning. Le r\u00e9glage", "start": 1289.7, "duration": 4.9}, {"text": "fin.", "start": 1294.6, "duration": 1.0}, {"text": "Le fine-tuning, c\u2019est l\u2019id\u00e9e de prendre\nun mod\u00e8le d\u00e9j\u00e0 entrain\u00e9, comme GPT, et", "start": 1295.6, "duration": 4.03}, {"text": "de le sp\u00e9cialiser en prolongeant son entrainement\nsur des textes bien choisis, qui ressemblent", "start": 1299.63, "duration": 5.409}, {"text": "plus \u00e0 ce qu\u2019on attend de lui.", "start": 1305.039, "duration": 1.801}, {"text": "[FONDATION FINETUNING L\u2019entrainement initial\nc\u2019est pour apprendre les grandes r\u00e8gles", "start": 1306.84, "duration": 2.51}, {"text": "de vocabulaire, de syntaxe, de grammaire,\nde relations entre les mots etc. C\u2019est pour", "start": 1309.35, "duration": 3.91}, {"text": "\u00e7a qu\u2019on parle d\u2019un mod\u00e8le de fondation.\nEt ensuite on sp\u00e9cialise le mod\u00e8le sur la", "start": 1313.26, "duration": 4.49}, {"text": "t\u00e2che qui nous int\u00e9resse vraiment gr\u00e2ce\n\u00e0 du finetuning.]", "start": 1317.75, "duration": 3.059}, {"text": "OpenAI a ainsi cr\u00e9\u00e9 InstructGPT, qui a \u00e9t\u00e9\n\u00ab\u00a0fine-tun\u00e9\u00a0\u00bb \u00e0 partir de GPT en \u00e9tant", "start": 1320.809, "duration": 6.451}, {"text": "expos\u00e9 \u00e0 des r\u00e9ponses r\u00e9dig\u00e9es par des\nhumains, et qui correspondaient au style qu\u2019on", "start": 1327.26, "duration": 4.62}, {"text": "attendrait d\u2019un chatbot utile et bienveillant.\nCette phase correspond donc \u00e0 un apprentissage", "start": 1331.88, "duration": 4.09}, {"text": "supervis\u00e9 plus classique, puisque l\u2019on\nutilise cette fois bien des donn\u00e9es cr\u00e9es", "start": 1335.97, "duration": 3.97}, {"text": "\u00e0 la main par des humains.", "start": 1339.94, "duration": 2.229}, {"text": "En combinant preprompt et finetuning, on arrive\n\u00e0 des r\u00e9sultats plus proches de ce qui est", "start": 1342.169, "duration": 4.88}, {"text": "attendu d\u2019un chatbot. Mais pour augmenter\nencore la qualit\u00e9, OpenAI a utilis\u00e9 en plus", "start": 1347.049, "duration": 4.881}, {"text": "une troisi\u00e8me technique : l\u2019apprentissage\npar renforcement avec feedback humain.", "start": 1351.93, "duration": 5.64}, {"text": "[jingle]", "start": 1357.57, "duration": 1.76}, {"text": "Pour permettre \u00e0 ChatGPT de proposer des\nr\u00e9ponses encore plus pertinentes, OpenAI", "start": 1359.33, "duration": 6.77}, {"text": "a ajout\u00e9 une troisi\u00e8me couche d'apprentissage,\nutilisant cette fois ce qu'on appelle l'apprentissage", "start": 1366.1, "duration": 4.66}, {"text": "par renforcement. L'id\u00e9e est de partir de\nr\u00e9ponses fournies par ChatGPT \u00e0 certaines", "start": 1370.76, "duration": 4.9}, {"text": "questions, et de faire \u00e9valuer ces r\u00e9ponses\npar des humains.", "start": 1375.66, "duration": 3.269}, {"text": "Ca n\u2019est pas comme la phase de finetuning\no\u00f9 des humains devaient carr\u00e9ment proposer", "start": 1378.929, "duration": 3.73}, {"text": "des r\u00e9ponses, l\u00e0 ils doivent juste juger\nles r\u00e9ponses que fournit ChatGPT. Une fa\u00e7on", "start": 1382.659, "duration": 5.421}, {"text": "simple, ce serait de leur demander de noter\nla qualit\u00e9 de la r\u00e9ponse, par exemple entre", "start": 1388.08, "duration": 3.91}, {"text": "0 et 20.", "start": 1391.99, "duration": 1.0}, {"text": "[RLHF En pratique comme tout le monde n'a\npas les m\u00eames \u00e9chelles de notation, on proc\u00e8de", "start": 1392.99, "duration": 3.62}, {"text": "plut\u00f4t par comparaison : pour une m\u00eame question,\non demande \u00e0 un humain de comparer diff\u00e9rentes", "start": 1396.61, "duration": 5.26}, {"text": "r\u00e9ponses produites par ChatGPT, et de les\nclasser entre elles.", "start": 1401.87, "duration": 3.77}, {"text": "A partir de ces \u00e9valuations, on peut entrainer\nce qu'on appelle un mod\u00e8le de r\u00e9compense,", "start": 1405.64, "duration": 5.2}, {"text": "qui va servir \u00e0 aider le mod\u00e8le de langage\n\u00e0 s\u2019orienter vers des r\u00e9ponses qui ressemblent", "start": 1410.84, "duration": 4.35}, {"text": "\u00e0 celles qu\u2019attendent ou que pr\u00e9f\u00e8rent\nles humains. Du moins les humains qui ont", "start": 1415.19, "duration": 3.82}, {"text": "fait les \u00e9valuations dans cette phase d\u2019apprentissage\npar renforcement.]", "start": 1419.01, "duration": 4.59}, {"text": "Cette phase est d'ailleurs aussi une fa\u00e7on\n\u00e0 ce stade de s'assurer que le mod\u00e8le ne", "start": 1423.6, "duration": 5.0}, {"text": "sort pas de r\u00e9ponses qui pourraient \u00eatre\njug\u00e9es ill\u00e9gales, dangereuses, haineuses", "start": 1428.6, "duration": 4.03}, {"text": "ou tout simplement inappropri\u00e9es pour l'usage\nauquel il est destin\u00e9.", "start": 1432.63, "duration": 3.56}, {"text": "[RESUME Si on combine donc l'ensemble des\ningr\u00e9dients qu\u2019on a mentionn\u00e9 : fine-tuning,", "start": 1436.19, "duration": 4.83}, {"text": "apprentissage par renforcement avec feedback\nhumain, et preprompt, on comprend qu\u2019il", "start": 1441.02, "duration": 3.78}, {"text": "est possible de sp\u00e9cialiser un mod\u00e8le de\nfondation.", "start": 1444.8, "duration": 2.67}, {"text": "Et d\u2019en faire ainsi un chatbot comme ChatGPT,\nqui soit plus pertinent, utile et plus respectueux", "start": 1447.47, "duration": 6.26}, {"text": "que GPT, qui avait simplement ingurgit\u00e9 tous\nles textes d\u2019internet.]", "start": 1453.73, "duration": 3.88}, {"text": "Alors \u00e0 l'issue de tout \u00e7a : qu'est-ce qu'il\nfaut penser de ChatGPT ? Sur des questions", "start": 1457.61, "duration": 4.37}, {"text": "ayant une r\u00e9ponse simple et d\u00e9j\u00e0 bien document\u00e9e,\nil fonctionne tr\u00e8s bien. Mais en soi \u00e7a", "start": 1461.98, "duration": 4.059}, {"text": "n'apporte pas grand chose de plus que Wikip\u00e9dia\nou une recherche Google.", "start": 1466.039, "duration": 3.861}, {"text": "\u2028Ce que l'on sait des mod\u00e8les de machine\nlearning, c'est qu'il sont souvent assez bons", "start": 1469.9, "duration": 3.95}, {"text": "pour interpoler, c'est-\u00e0-dire bien traiter\nune situation nouvelle, mais qui soit suffisamment", "start": 1473.85, "duration": 5.679}, {"text": "proche d'un ensemble de cas qu'ils ont pu\nvoir dans leur entrainement.", "start": 1479.529, "duration": 3.26}, {"text": "Et on peut souvent le v\u00e9rifier ici : le mod\u00e8le\npeut produire des r\u00e9ponses int\u00e9ressantes", "start": 1482.789, "duration": 4.461}, {"text": "et m\u00eame inventives \u00e0 des questions originales\nou pas forc\u00e9ment toujours bien formul\u00e9es.", "start": 1487.25, "duration": 4.799}, {"text": "On d\u00e9crit parfois l'intelligence ou la cr\u00e9ativit\u00e9\ncomme la facilit\u00e9 \u00e0 relier des choses qui", "start": 1492.049, "duration": 5.121}, {"text": "n\u2019ont pas forc\u00e9ment de lien apparent ou\n\u00e9vident. Et de ce point de vue l\u00e0, c\u2019est", "start": 1497.17, "duration": 4.2}, {"text": "int\u00e9ressant de voir que ChatGPT montre des\nsignes ind\u00e9niables de certaines de ces capacit\u00e9s.", "start": 1501.37, "duration": 4.48}, {"text": "On pourrait passer des heures \u00e0 passer en\nrevue ce que ChatGPT fait bien, et ce sur", "start": 1505.85, "duration": 5.42}, {"text": "quoi il \u00e9choue lamentablement. Mais d'une\npart vous en avez certainement d\u00e9j\u00e0 vu passer", "start": 1511.27, "duration": 3.51}, {"text": "plein d'exemples, d'autre part, \u00e7a bouge\ntellement vite que tout ce que je pourrai", "start": 1514.78, "duration": 3.8}, {"text": "raconter sera peut-\u00eatre caduc dans quelques\nsemaines.", "start": 1518.58, "duration": 2.579}, {"text": "Un point sur lequel j\u2019ai envie quand m\u00eame\ncommenter, et sur lequel ChatGPT est particuli\u00e8rement", "start": 1521.159, "duration": 4.251}, {"text": "mauvais, c'est le fait de citer des sources.\nSi on le fait parler d'un ph\u00e9nom\u00e8ne scientifique,", "start": 1525.41, "duration": 4.87}, {"text": "et qu'on lui demande les r\u00e9f\u00e9rences des\npublications d'o\u00f9 il tire ses conclusions,", "start": 1530.28, "duration": 4.43}, {"text": "on obtient la plupart du temps des articles\ncompl\u00e8tement invent\u00e9s qui n'existent absolument", "start": 1534.71, "duration": 5.03}, {"text": "pas.", "start": 1539.74, "duration": 1.0}, {"text": "Ca peut paraitre assez emb\u00eatant, mais \u00e0\nnouveau si on r\u00e9fl\u00e9chit \u00e0 comment fonctionne", "start": 1540.74, "duration": 4.45}, {"text": "le mod\u00e8le, on l'explique assez bien. GPT\nne raisonne pas, il ne cherche pas sur Internet,", "start": 1545.19, "duration": 4.72}, {"text": "il n'a pas de m\u00e9moire explicite : il se contente\nde g\u00e9n\u00e9rer des textes plausibles dont les", "start": 1549.91, "duration": 4.8}, {"text": "mots collent bien ensemble.", "start": 1554.71, "duration": 1.56}, {"text": "Et quand on regarde le format des citations\nd'articles scientifiques, franchement tout", "start": 1556.27, "duration": 4.529}, {"text": "se ressemble. Et donc n'importe quel s\u00e9quence\nde mots qui respecte vaguement le format standard,", "start": 1560.799, "duration": 5.571}, {"text": "\u00e7a passera \u00e0 ses yeux comme une compl\u00e9tion\ntout \u00e0 fait cr\u00e9dible pour faire office de", "start": 1566.37, "duration": 5.37}, {"text": "r\u00e9f\u00e9rence scientifique.", "start": 1571.74, "duration": 1.02}, {"text": "D'autant que bien souvent dans un article\nscientifique, les r\u00e9f\u00e9rences sont group\u00e9es", "start": 1572.76, "duration": 3.419}, {"text": "en un gros paquet \u00e0 la fin, et en lisant\nuniquement ces sections, on a bien du mal", "start": 1576.179, "duration": 4.48}, {"text": "\u00e0 deviner le contexte de chacune de ces citations.", "start": 1580.659, "duration": 3.371}, {"text": "Et pour ChatGPT, c'est un peu pareil, une\nr\u00e9f\u00e9rence random avec \u00e0 peu pr\u00e8s les bons", "start": 1584.03, "duration": 4.1}, {"text": "auteurs et le nom d'un journal qui existe\nvraiment, il invente un volume et un num\u00e9ro", "start": 1588.13, "duration": 5.08}, {"text": "de page, et ce sera jug\u00e9 comme parfaitement\nraisonnable \u00e9tant donn\u00e9 son mode de fonctionnement.", "start": 1593.21, "duration": 4.949}, {"text": "Ce probl\u00e8me sp\u00e9cifique des sources semble\nassez difficile \u00e0 r\u00e9soudre en se basant", "start": 1598.159, "duration": 4.661}, {"text": "uniquement sur le principe d'un mod\u00e8le de\nlangage. Mais on peut imaginer qu'en couplant", "start": 1602.82, "duration": 4.229}, {"text": "ces mod\u00e8les a des m\u00e9canismes de recherche\nsur Internet ou dans des bases de donn\u00e9es,", "start": 1607.049, "duration": 4.301}, {"text": "cette question des sources invent\u00e9es finira\npar \u00eatre r\u00e9solue.", "start": 1611.35, "duration": 2.84}, {"text": "Merci d\u2019avoir suivi cette vid\u00e9o, comme\ntoujours abonnez-vous, rejoignez aussi le", "start": 1614.19, "duration": 4.959}, {"text": "Discord de science \u00e9tonnante, le lien est\nen description, c\u2019est le meilleur moyen", "start": 1619.149, "duration": 2.921}, {"text": "d\u2019avoir des nouvelles qui ne soient pas\nfiltr\u00e9es par l\u2019algo Youtube, et on se retrouve", "start": 1622.07, "duration": 4.18}, {"text": "tr\u00e8s vite pour une nouvelle vid\u00e9o. A bient\u00f4t.\nPOSE MINIATURE", "start": 1626.25, "duration": 1.85}]}