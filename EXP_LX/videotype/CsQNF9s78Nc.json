{"label": "education", "transcript": [{"text": "Que ce soit les chatbox, les logiciels\nde traduction automatique", "start": 0.001, "duration": 3.519}, {"text": "ou encore les enceintes connect\u00e9es,", "start": 3.72, "duration": 1.72}, {"text": "de plus en plus d'applications semblent\n\u00eatre capables de comprendre notre langue.", "start": 5.64, "duration": 4.52}, {"text": "Jusqu'\u00e0 une p\u00e9riode r\u00e9cente, quand on voulait\ns'adresser \u00e0 un ordinateur,", "start": 10.36, "duration": 2.28}, {"text": "le seul moyen \u00e9tait d'utiliser un\n\"langage de programmation\",", "start": 12.84, "duration": 3.4}, {"text": "un truc artificiel, tr\u00e8s formalis\u00e9,\navec des r\u00e8gles pr\u00e9cises.", "start": 16.44, "duration": 3.8}, {"text": "Mais de plus en plus il semblerait que gr\u00e2ce\naux m\u00e9thodes d'intelligence artificielle,", "start": 20.44, "duration": 3.8}, {"text": "les machines soient capables de comprendre\nce qu'on appelle le \"langage naturel\".", "start": 24.44, "duration": 3.84}, {"text": "C'est-\u00e0-dire les langues que les humains\nutilisent au quotidien,", "start": 28.48, "duration": 2.76}, {"text": "comme le fran\u00e7ais ou l'anglais.", "start": 31.44, "duration": 2.24}, {"text": "Est-ce qu'on peut dire que les IA comprennent\nvraiment ce qu'on leur raconte,", "start": 33.88, "duration": 2.84}, {"text": "qu'elles sont capables de penser\navec les m\u00eames mots que nous\u00a0?", "start": 36.92, "duration": 3.32}, {"text": "Eh bien, pour s'en faire une id\u00e9e on va\nse pencher sur les m\u00e9thodes utilis\u00e9es", "start": 40.44, "duration": 2.48}, {"text": "par ces algorithmes pour manipuler\nle langage naturel.", "start": 43.12, "duration": 3.94}, {"text": "[Jingle]", "start": 47.28, "duration": 2.56}, {"text": "Dans cette vid\u00e9o on va essentiellement\nparler des techniques d'IA", "start": 53.0, "duration": 3.04}, {"text": "qu'on regroupe sous le terme de\n\"machine learning\",", "start": 56.24, "duration": 2.4}, {"text": "l'apprentissage automatique,", "start": 58.84, "duration": 1.6}, {"text": "et plus sp\u00e9cifiquement des fameuses\ntechniques de \"deep learning\",", "start": 60.64, "duration": 3.12}, {"text": "l'apprentissage profond.", "start": 63.76, "duration": 1.32}, {"text": "Pour ceux que \u00e7a int\u00e9resse, j'avais d\u00e9j\u00e0 fait\nun \u00e9pisode sur le sujet,", "start": 65.08, "duration": 3.16}, {"text": "mais je vais quand m\u00eame rappeler\nles principes de base.", "start": 68.44, "duration": 2.72}, {"text": "L'id\u00e9e est de consid\u00e9rer un algorithme\nqui est en gros une fonction,", "start": 71.36, "duration": 3.36}, {"text": "c'est-\u00e0-dire comme une machine math\u00e9matique\n\u00e0 qui on donne une entr\u00e9e X", "start": 74.92, "duration": 4.24}, {"text": "et qui va produire une certaine sortie Y.", "start": 79.36, "duration": 2.6}, {"text": "Et on va apprendre \u00e0 cet algorithme\n\u00e0 faire quelque chose qui nous int\u00e9resse.", "start": 82.16, "duration": 3.88}, {"text": "Prenons un cas concret classique\u00a0:\nimaginons qu'on veuille", "start": 86.24, "duration": 1.92}, {"text": "qu'un algorithme soit capable de reconnaitre\nce qu'il y a sur des images.", "start": 88.36, "duration": 3.72}, {"text": "En entr\u00e9e X on veut pouvoir\nlui donner des images", "start": 92.28, "duration": 2.16}, {"text": "et en sortie Y on attend pour chaque image,\nun mot qui la d\u00e9crit.", "start": 94.64, "duration": 3.92}, {"text": "Par exemple ici, on veut que l'algorithme\nnous r\u00e9ponde\u00a0: \"Chat\".", "start": 98.76, "duration": 2.92}, {"text": "Pour en arriver l\u00e0,\n\u00e7a se passe en deux temps,", "start": 101.88, "duration": 2.56}, {"text": "au d\u00e9part l'algorithme n'est pas entrain\u00e9,\nil r\u00e9pond donc n'importe quoi,", "start": 104.64, "duration": 3.92}, {"text": "donc dans la premi\u00e8re phase,\nla phase d'apprentissage,", "start": 108.76, "duration": 2.48}, {"text": "on va lui montrer des exemples de\nce qu'on voudrait qu'il fasse,", "start": 111.44, "duration": 2.84}, {"text": "par exemple en lui filant\nune base de donn\u00e9es", "start": 114.48, "duration": 2.08}, {"text": "de milliers d'images auxquelles\non a d\u00e9j\u00e0 associ\u00e9 les bons mots.", "start": 116.76, "duration": 3.92}, {"text": "Et, en voyant ces exemples, l'algorithme\nva se modifier progressivement", "start": 120.88, "duration": 3.4}, {"text": "pour s'adapter \u00e0 ce qu'on lui demande\nde faire.", "start": 124.48, "duration": 2.8}, {"text": "Dit comme \u00e7a, \u00e7a a l'air magique,\nun algorithme qui se modifie,", "start": 127.48, "duration": 3.0}, {"text": "mais math\u00e9matiquement \u00e7a se formalise bien.", "start": 130.68, "duration": 2.84}, {"text": "La fonction math\u00e9matique qui relie Y et X\ndans l'algorithme", "start": 133.72, "duration": 3.4}, {"text": "dispose d'une tr\u00e8s grande quantit\u00e9\nde param\u00e8tres,", "start": 137.32, "duration": 2.48}, {"text": "on les appelle des poids et on note \u00e7a\ng\u00e9n\u00e9ralement \"W\".", "start": 140.0, "duration": 2.96}, {"text": "Et voyez ces param\u00e8tres comme des boutons\nque l'algorithme peut tourner", "start": 143.16, "duration": 3.16}, {"text": "pour faire varier la fa\u00e7on dont Y\nest construit \u00e0 partir de X.", "start": 146.52, "duration": 4.56}, {"text": "Durant la phase d'apprentissage, ces poids\nsont ajust\u00e9s", "start": 151.28, "duration": 2.2}, {"text": "de mani\u00e8re \u00e0 coller aux exemples\nde la base de donn\u00e9es,", "start": 153.68, "duration": 2.6}, {"text": "\u00e7a peut prendre un certain temps\nen fonction de la taille de la base,", "start": 156.48, "duration": 2.68}, {"text": "du nombre de poids et de la complexit\u00e9\ndu probl\u00e8me.", "start": 159.36, "duration": 2.68}, {"text": "Et une fois cette phase termin\u00e9e,\nl'algorithme est pr\u00eat,", "start": 162.24, "duration": 2.8}, {"text": "il est entra\u00een\u00e9 et on peut s'en servir,\nc'est la phase d'utilisation.", "start": 165.24, "duration": 3.92}, {"text": "On lui pr\u00e9sente de nouvelles images,\nqu'il n'a jamais vues et,", "start": 169.36, "duration": 2.48}, {"text": "si tout fonctionne bien, il sera capable\nde reconna\u00eetre ce qu'il y a dessus.", "start": 172.04, "duration": 4.2}, {"text": "Voil\u00e0 pour les grands principe\ndu machine learning.", "start": 176.44, "duration": 2.56}, {"text": "L\u00e0, je vous ai pr\u00e9sent\u00e9 le truc d'une fa\u00e7on\nassez abstraite,", "start": 179.2, "duration": 2.28}, {"text": "je ne vous ai pas vraiment expliqu\u00e9\nce qu'on va utiliser", "start": 181.68, "duration": 2.04}, {"text": "comme fonction pour r\u00e9aliser tout ce travail.", "start": 183.92, "duration": 2.6}, {"text": "Ces derniers temps on utilise majoritairement\nles r\u00e9seaux de neurones", "start": 186.72, "duration": 3.36}, {"text": "et notamment les r\u00e9seaux dits \"profonds\"", "start": 190.28, "duration": 1.8}, {"text": "qui ont l'avantage d'\u00eatre \u00e0 la fois\ntr\u00e8s puissants et tr\u00e8s flexibles,", "start": 192.28, "duration": 4.04}, {"text": "mais la structure, l'architecture pr\u00e9cise\nde ces r\u00e9seaux", "start": 196.52, "duration": 2.88}, {"text": "doit souvent \u00eatre adapt\u00e9e au probl\u00e8me\nqu'on consid\u00e8re.", "start": 199.6, "duration": 2.92}, {"text": "Dans le cas de la reconnaissance d'image\non utilise", "start": 202.72, "duration": 1.6}, {"text": "ce qu'on appelle des r\u00e9seaux de convolution", "start": 204.52, "duration": 1.6}, {"text": "qui ont une capacit\u00e9 \u00e0 reconna\u00eetre\ndes choses int\u00e9ressantes", "start": 206.32, "duration": 3.32}, {"text": "dans une image en l'analysant successivement", "start": 209.84, "duration": 2.48}, {"text": "\u00e0 diff\u00e9rentes \u00e9chelles,\nd'une fa\u00e7on hi\u00e9rarchique.", "start": 212.52, "duration": 2.36}, {"text": "Par exemple sur cette image, un r\u00e9seau\nde convolution va d\u00e9tecter d'abord", "start": 215.08, "duration": 3.52}, {"text": "les variations de luminosit\u00e9\nd'un pixel \u00e0 l'autre,", "start": 218.8, "duration": 2.24}, {"text": "qui repr\u00e9sentent une fronti\u00e8re\nou un trait", "start": 221.24, "duration": 2.12}, {"text": "puis ces informations seront assembl\u00e9es\npour reconna\u00eetre", "start": 223.56, "duration": 2.88}, {"text": "des bouts de segments ou des morceaux\nde courbes,", "start": 226.64, "duration": 1.76}, {"text": "puis au niveau au dessus en combinant\nles segments et les courbes,", "start": 228.6, "duration": 4.08}, {"text": "il peut reconna\u00eetre des formes g\u00e9om\u00e9triques.", "start": 232.88, "duration": 2.56}, {"text": "Et c'est en combinant \u00e0 nouveau\nces caract\u00e9ristiques globales", "start": 235.64, "duration": 2.52}, {"text": "que le r\u00e9seau peut finalement apprendre\n\u00e0 reconna\u00eetre des images compl\u00e8tes.", "start": 238.36, "duration": 4.36}, {"text": "Alors \u00e9videmment je vous le d\u00e9cris de fa\u00e7on\nassez sommaire,", "start": 242.92, "duration": 2.08}, {"text": "mais on peut imaginer que cette fa\u00e7on\nhi\u00e9rarchique d'analyser", "start": 245.2, "duration": 3.2}, {"text": "aux diff\u00e9rentes \u00e9chelles ressemble \u00e0 la fa\u00e7on\ndont notre vision \u00e0 nous fonctionne.", "start": 248.6, "duration": 4.68}, {"text": "Il y a quand m\u00eame un point important\nque j'ai pass\u00e9 sous silence\u00a0:", "start": 253.48, "duration": 2.32}, {"text": "ces algorithmes de r\u00e9seaux de neurones,\nje vous l'ai dit, n'ont rien de magique,", "start": 256.0, "duration": 2.96}, {"text": "ce sont des fonctions math\u00e9matiques,", "start": 259.16, "duration": 1.84}, {"text": "on les construit \u00e0 partir d'op\u00e9rations\nsimples comme l'addition,", "start": 261.2, "duration": 2.84}, {"text": "la multiplication la fonction\nexponentielle, etc.", "start": 264.24, "duration": 2.48}, {"text": "\u00c7a signifie que la seule chose que ces\nr\u00e9seaux peuvent manipuler", "start": 266.92, "duration": 3.72}, {"text": "eh bien ce sont des nombres.", "start": 270.84, "duration": 1.92}, {"text": "Alors l\u00e0 je vous ai dit que pour faire\nde la reconnaissance d'image", "start": 272.96, "duration": 2.44}, {"text": "on prenait des images en entr\u00e9e et on avait\ndes mots en sortie, alors, comment on fait\u00a0?", "start": 275.6, "duration": 4.12}, {"text": "Pour les images c'est assez simple,\non prend les pixels,", "start": 279.92, "duration": 3.64}, {"text": "on regarde leur luminosit\u00e9 ou bien\nleurs couleurs", "start": 283.76, "duration": 2.12}, {"text": "en rouge/vert/bleu et \u00e7a nous donne\ndes nombres.", "start": 286.08, "duration": 2.04}, {"text": "Pour une image de 400 par 400 pixels\nen couleur,", "start": 288.32, "duration": 3.28}, {"text": "\u00e7a fait pas loin de 500 000 nombres\nen entr\u00e9e,", "start": 291.8, "duration": 2.8}, {"text": "c'est beaucoup, mais au moins ce sont\ndes nombres que le r\u00e9seau peut manipuler.", "start": 294.8, "duration": 3.8}, {"text": "Et pour la sortie\u00a0?", "start": 298.8, "duration": 0.84}, {"text": "Eh bien notre r\u00e9seau ne parle ni anglais\nni fran\u00e7ais,", "start": 299.64, "duration": 2.56}, {"text": "il ne sait pas \u00e9crire des mots comme\n\"chat\" ou \"voiture\".", "start": 302.4, "duration": 2.72}, {"text": "Donc il faut lui cadrer les choses,", "start": 305.32, "duration": 1.68}, {"text": "pour faire \u00e7a on va se fixer \u00e0 l'avance\nune liste de mots possibles", "start": 307.2, "duration": 4.8}, {"text": "par exemple 1 000 mots tr\u00e8s courants", "start": 312.2, "duration": 1.84}, {"text": "qui d\u00e9crivent des objets, des lieux,\ndes animaux", "start": 314.24, "duration": 2.48}, {"text": "chacun de ces mots re\u00e7oit un num\u00e9ro\nde 1 \u00e0 1 000,", "start": 316.92, "duration": 2.84}, {"text": "par exemple sa position alphab\u00e9tique\ndans la liste et quand on pr\u00e9sente", "start": 319.96, "duration": 3.44}, {"text": "la base de donn\u00e9es d'exemple \u00e0 l'algorithme,\non utilise ces num\u00e9ros.", "start": 323.6, "duration": 4.2}, {"text": "Une fois le r\u00e9seau entra\u00een\u00e9, chaque fois\nqu'on lui pr\u00e9sentera une image,", "start": 328.0, "duration": 2.88}, {"text": "il nous donnera un num\u00e9ro entre 1 et 1 000", "start": 331.08, "duration": 2.36}, {"text": "correspondant \u00e0 ce qu'il pense\navoir reconnu sur l'image.", "start": 333.64, "duration": 2.92}, {"text": "Et m\u00eame, g\u00e9n\u00e9ralement les algorithmes\nfont un peu mieux que \u00e7a,", "start": 336.76, "duration": 3.24}, {"text": "en sortie ils vont plut\u00f4t sortir une longue\nliste de de 1 000 nombre entre 0 et 1", "start": 340.2, "duration": 4.84}, {"text": "qui correspondent \u00e0 la probabilit\u00e9 estim\u00e9e\nde chacun des 1 000 mots,", "start": 345.24, "duration": 3.48}, {"text": "par exemple sur cette image la r\u00e9ponse\nsera peut-\u00eatre \"chat\" \u00e0 97%", "start": 348.92, "duration": 4.68}, {"text": "\"chien\" \u00e0 2% et canard \u00e0 1%", "start": 353.8, "duration": 2.64}, {"text": "et puis tout le reste \"voiture, avion,\nchaise, etc.\" presque \u00e0 0%", "start": 356.64, "duration": 3.08}, {"text": "Petit point vocabulaire\u00a0: cette longue liste\nde nombre en sortie,", "start": 359.92, "duration": 4.68}, {"text": "on va appeler \u00e7a un \"vecteur\", je vais\nplusieurs fois utiliser ce terme", "start": 364.8, "duration": 3.44}, {"text": "et \u00e7a d\u00e9signera \u00e0 chaque fois juste\nune grosse liste de nombre r\u00e9els.", "start": 368.44, "duration": 4.32}, {"text": "\u00c7a doit vous sembler bizarre car \u00e7a semble\nassez loin des vecteurs", "start": 372.96, "duration": 3.04}, {"text": "repr\u00e9sent\u00e9s par des petites fl\u00e8ches", "start": 376.2, "duration": 1.28}, {"text": "qu'on utilise pour faire de la g\u00e9om\u00e9trie,\nmais il y a un lien.", "start": 377.68, "duration": 2.44}, {"text": "En g\u00e9om\u00e9trie si vous avez un quadrillage,", "start": 380.32, "duration": 2.52}, {"text": "vous pouvez repr\u00e9senter un vecteur\npar ses coordonn\u00e9es, il vous en faudra deux,", "start": 383.04, "duration": 3.72}, {"text": "pour un vecteur du plan c'est une liste\nde deux nombres r\u00e9els,", "start": 386.96, "duration": 3.72}, {"text": "en trois dimensions il vous en faudra trois.", "start": 390.88, "duration": 2.36}, {"text": "Eh bien on va juste \u00e9tendre le principe\nen disant", "start": 393.44, "duration": 2.88}, {"text": "que n'importe quelle liste de nombre,\nm\u00eame s'il y en a 1000, c'est un vecteur,", "start": 396.52, "duration": 3.48}, {"text": "un vecteur dans un espace \u00e0 1000 dimensions.", "start": 400.2, "duration": 2.28}, {"text": "Oui, \u00e7a a l'air un peu vertigineux comme \u00e7a,\nmais vous allez voir, \u00e7a va bien se passer.", "start": 402.68, "duration": 3.48}, {"text": "Bien, tout ce que je vous ai d\u00e9crit l\u00e0,\n\u00e7a fonctionne tr\u00e8s bien pour des images,", "start": 406.36, "duration": 3.4}, {"text": "les capacit\u00e9s de reconnaissance\ndes algorithmes sont aujourd'hui", "start": 409.96, "duration": 2.96}, {"text": "au m\u00eame niveau que celles des humains,", "start": 413.12, "duration": 1.54}, {"text": "mais pour reconna\u00eetre et comprendre\ndes phrases en langage naturel,", "start": 414.76, "duration": 3.68}, {"text": "eh bien \u00e7a va \u00eatre plus compliqu\u00e9.", "start": 418.64, "duration": 1.52}, {"text": "Quand on entraine un algorithme\n\u00e0 reconna\u00eetre des images,", "start": 420.16, "duration": 3.08}, {"text": "on doit choisir une taille fixe,\npar exemple 400 pixels par 400 pixels,", "start": 423.44, "duration": 3.48}, {"text": "si on a une image de taille diff\u00e9rente,", "start": 427.12, "duration": 2.04}, {"text": "on peut toujours la mettre \u00e0 l'\u00e9chelle\nou bien tailler dedans.", "start": 429.36, "duration": 2.8}, {"text": "Le probl\u00e8me des phrases c'est qu'elles ont\ndes tailles tr\u00e8s variables", "start": 432.36, "duration": 2.64}, {"text": "et qu'on ne peut pas faire\nce genre de choses,", "start": 435.2, "duration": 1.4}, {"text": "si on entra\u00eene un algorithme pour une taille\nfixe, disons des phrases de 10 mots,", "start": 436.8, "duration": 3.96}, {"text": "on ne peut pas compresser ou d\u00e9couper\nles phrases plus longues", "start": 440.96, "duration": 2.88}, {"text": "en plusieurs morceaux sans risquer\nd'en perdre le sens.", "start": 444.04, "duration": 2.32}, {"text": "Et puis dans une phrase, l'ordre joue\nun r\u00f4le essentiel,", "start": 446.56, "duration": 3.16}, {"text": "ce qui se passe \u00e0 un bout de la phrase\npeut compl\u00e8tement modifier", "start": 449.92, "duration": 2.48}, {"text": "le sens de ce qu'il y avait au d\u00e9but.", "start": 452.6, "duration": 1.2}, {"text": "\u00c7a se voit bien dans un des premiers\nprobl\u00e8mes auxquels on s'attaque", "start": 454.0, "duration": 3.16}, {"text": "quand on essaie de manipuler\ndu langage naturel,", "start": 457.36, "duration": 1.96}, {"text": "ce qu'on appelle parfois la classification\ndes sentiments, ou des opinions.", "start": 459.52, "duration": 3.72}, {"text": "Imaginez que vous lisiez un commentaire\nsur internet", "start": 463.44, "duration": 3.16}, {"text": "\u00e0 propos d'un produit ou\nd'une cha\u00eene youtube tiens\u00a0!", "start": 466.8, "duration": 2.72}, {"text": "et qu'on vous demande de juger\nautomatiquement", "start": 469.72, "duration": 2.56}, {"text": "si ce commentaire est positif,\nn\u00e9gatif ou neutre.", "start": 472.48, "duration": 3.24}, {"text": "Eh bien on peut voir \u00e7a comme un probl\u00e8me\nde machine learning", "start": 475.92, "duration": 3.08}, {"text": "En entr\u00e9e on file un texte et, en sortie,\non veut des probabilit\u00e9s estim\u00e9es", "start": 479.2, "duration": 4.2}, {"text": "que le texte soit positif, n\u00e9gatif,\nneutre etc.", "start": 483.6, "duration": 2.6}, {"text": "\u00c0 premi\u00e8re vue \u00e7a ne para\u00eet pas\ntr\u00e8s compliqu\u00e9,", "start": 486.4, "duration": 2.84}, {"text": "on peut se faire une bonne id\u00e9e\nde la tonalit\u00e9 d'un commentaire,", "start": 489.44, "duration": 2.72}, {"text": "juste avec la pr\u00e9sence de mots cl\u00e9s\ndu genre \"mauvais\",", "start": 492.36, "duration": 2.64}, {"text": "mais \u00e0 y regarder de plus pr\u00e9s,\nc'est pas si simple,", "start": 495.2, "duration": 2.76}, {"text": "il peut y avoir des formulations comme\u00a0:", "start": 498.42, "duration": 2.12}, {"text": "H\u00e9, il y a le mot \"mauvais\", mais\nc'est un commentaire plut\u00f4t positif,", "start": 504.1, "duration": 4.3}, {"text": "donc la s\u00e9quence enti\u00e8re des mots\nest tr\u00e8s importante pour saisir le sens.", "start": 508.6, "duration": 4.6}, {"text": "La classification automatique des sentiments", "start": 513.4, "duration": 2.08}, {"text": "n'est qu'un exemple de probl\u00e8me\nqu'on peut essayer de r\u00e9soudre", "start": 515.68, "duration": 2.64}, {"text": "par des algorithmes de traitement\ndu langage naturel", "start": 518.52, "duration": 2.4}, {"text": "Mais il y en a plein d'autres,\nil y a la traduction automatique bien s\u00fbr,", "start": 521.12, "duration": 3.44}, {"text": "o\u00f9 on essaie de prendre une phrase en entr\u00e9e\ndans une langue", "start": 524.76, "duration": 2.48}, {"text": "et d'avoir en sortie la m\u00eame phrase\ndans une autre langue.", "start": 527.44, "duration": 3.12}, {"text": "Il y a le r\u00e9sum\u00e9 de texte, o\u00f9 on donne\nun long texte en entr\u00e9e", "start": 530.76, "duration": 3.08}, {"text": "et on veut r\u00e9cup\u00e9rer en sortie un r\u00e9sum\u00e9 en,\ndisons quelques phrases seulement.", "start": 534.04, "duration": 3.88}, {"text": "Il y a aussi la g\u00e9n\u00e9ration de texte\no\u00f9 on veut cette fois un algorithme", "start": 538.12, "duration": 2.48}, {"text": "qui soit capable de prolonger un texte\nqu'on a commenc\u00e9 \u00e9crire.", "start": 540.8, "duration": 3.84}, {"text": "Tous ces probl\u00e8mes appartiennent\n\u00e0 cette discipline qu'on appelle", "start": 544.84, "duration": 2.28}, {"text": "le traitement du langage naturel,\non utilise souvent l'abr\u00e9viation", "start": 547.32, "duration": 3.16}, {"text": "NLP en anglais pour\u00a0:\nNatural Language Processing.", "start": 550.68, "duration": 2.12}, {"text": "[Jingle]", "start": 553.0, "duration": 2.76}, {"text": "Pour commencer, comme on l'a dit\ntout \u00e0 l'heure,", "start": 556.78, "duration": 1.54}, {"text": "les algorithmes qu'on utilise ne savent\npas manipuler des mots en tant que tels,", "start": 558.52, "duration": 2.92}, {"text": "ils ne manipulent que des nombres.", "start": 561.64, "duration": 1.64}, {"text": "Dans le cas de la reconnaissance d'image\non se fixe un certain nombre de mot,", "start": 563.48, "duration": 2.8}, {"text": "typiquement 1 000, on les num\u00e9rote et\non choisit de ne faire qu'avec ceux-ci.", "start": 566.48, "duration": 4.56}, {"text": "\u00c7a veut dire que dans la liste de mots\non aura certainement le mot \"piano\"", "start": 571.24, "duration": 2.88}, {"text": "qui est courant, mais pas forc\u00e9ment\nle mot \"clavecin\"", "start": 574.32, "duration": 3.12}, {"text": "et donc, si une image repr\u00e9sente un clavecin\neh bien elle sera certainement class\u00e9e", "start": 577.64, "duration": 3.32}, {"text": "comme \u00e9tant un piano, mais c'est pas\nforc\u00e9ment tr\u00e8s grave.", "start": 581.16, "duration": 3.44}, {"text": "Mais pour faire de la traduction par exemple,\non ne peut pas faire \u00e7a", "start": 584.8, "duration": 2.36}, {"text": "et se limiter \u00e0 seulement 1 000 mots courants,", "start": 587.36, "duration": 2.12}, {"text": "si dans la phrase \u00e0 traduire il y a le mot\n\"clavecin\"", "start": 589.68, "duration": 2.32}, {"text": "l'algorithme de traduction ne peut pas dire\u00a0:", "start": 592.2, "duration": 1.04}, {"text": "\"ben ce mot-l\u00e0 je ne le connais pas\ndonc je traduis pas\".", "start": 593.44, "duration": 2.96}, {"text": "Alors l\u00e0, vous allez me dire \"facile hein,\nau lieu de prendre une liste de 1 000 mots,", "start": 596.6, "duration": 2.48}, {"text": "on n'a qu'\u00e0 prendre un dictionnaire complet,\navec disons les 50 000 mots les plus courants,", "start": 599.28, "duration": 4.08}, {"text": "\u00e7a devrait le faire, on repr\u00e9sente\nchaque mot avec un nombre", "start": 603.56, "duration": 2.84}, {"text": "entre 1 et 50 000 par exemple sa position\nalphab\u00e9tique dans le dictionnaire", "start": 606.6, "duration": 3.76}, {"text": "et puis on est bon\u00a0! \"", "start": 610.56, "duration": 0.68}, {"text": "Alors oui, mais \u00e7a pose deux probl\u00e8mes,\nd\u00e9j\u00e0 passer de 1 000 \u00e0 50 000", "start": 611.44, "duration": 3.12}, {"text": "\u00e7a fait une bonne diff\u00e9rence de taille\ndonc pour les algorithmes", "start": 614.76, "duration": 2.32}, {"text": "\u00e7a complique pas mal la t\u00e2che,\net puis surtout", "start": 617.28, "duration": 2.36}, {"text": "num\u00e9roter par exemple alphab\u00e9tiquement\nles mots \u00e7a complique les choses.", "start": 619.84, "duration": 3.92}, {"text": "Si on fait comme on vient de dire,\nle mot \"piano\" sera par exemple cod\u00e9", "start": 623.96, "duration": 3.36}, {"text": "avec le num\u00e9ro 32 121 et clavecin\navec le num\u00e9ro 4 164", "start": 627.52, "duration": 5.2}, {"text": "et donc ils seront trait\u00e9s de mani\u00e8re\ncompl\u00e8tement diff\u00e9rentes", "start": 632.92, "duration": 2.08}, {"text": "comme deux concepts totalement ind\u00e9pendants,\nor nous, on sait qu'il y a des similarit\u00e9s.", "start": 635.2, "duration": 5.28}, {"text": "Si je vous dis\u00a0:\n\"il plaqua un accord sur le clavecin\"", "start": 640.68, "duration": 3.4}, {"text": "vous comprenez le sens de la phrase", "start": 644.28, "duration": 1.44}, {"text": "m\u00eame si vous n'aviez jamais entendu\nde votre vie", "start": 645.92, "duration": 2.32}, {"text": "l'id\u00e9e de plaquer un accord sur un clavecin,", "start": 648.44, "duration": 2.16}, {"text": "mais vous l'avez probablement d\u00e9j\u00e0 entendue\nen parlant d'un piano,", "start": 650.8, "duration": 2.84}, {"text": "vous savez qu'un clavecin et un piano\npartagent des similarit\u00e9s,", "start": 653.84, "duration": 2.76}, {"text": "ce sont des instruments,\nils ont un clavier, etc.", "start": 656.8, "duration": 1.96}, {"text": "Donc dans notre fa\u00e7on de comprendre\ndes phrases en langage naturel,", "start": 658.96, "duration": 2.0}, {"text": "on exploite des similarit\u00e9s\nou des proximit\u00e9s de sens.", "start": 661.16, "duration": 3.12}, {"text": "Si notre algorithme on lui file\njuste 50 000 mots", "start": 664.48, "duration": 1.88}, {"text": "comme des num\u00e9ros sans relations, ben\nil ne pourra pas faire \u00e7a,", "start": 666.56, "duration": 2.84}, {"text": "il ne pourra pas utiliser ce qu'il sait\ndes pianos", "start": 669.6, "duration": 1.72}, {"text": "pour l'appliquer aussi aux clavecins\nsi besoin.", "start": 671.52, "duration": 3.04}, {"text": "Ce qu'il faudrait faire, c'est coder\nles mots avec un principe", "start": 674.76, "duration": 2.36}, {"text": "qui respecte leur sens et la fa\u00e7on\ndont ils sont utilis\u00e9s", "start": 677.32, "duration": 3.6}, {"text": "Or, comme le disait le philosophe\nWittgenstein\u00a0:", "start": 681.12, "duration": 2.28}, {"text": "\"la signification d'un mot c'est\nson usage dans le langage\".", "start": 683.6, "duration": 3.92}, {"text": "Alors oui Monsieur Phi m'a dit que c'\u00e9tait\ntr\u00e8s chic de citer Wittgenstein.", "start": 687.72, "duration": 3.24}, {"text": "Donc pour essayer d'attribuer \u00e0 chaque mot\nun nombre qui le repr\u00e9sente bien,", "start": 691.16, "duration": 3.24}, {"text": "eh bien il faut qu'on essaie de tenir compte\nde son contexte d'utilisation.", "start": 694.6, "duration": 3.16}, {"text": "Prenons un nouvel exemple\u00a0: Le mot \"Chat\",", "start": 697.96, "duration": 3.4}, {"text": "on a envie que le mot \"Chien\" soit\nprobablement repr\u00e9sent\u00e9 assez proche de lui,", "start": 701.56, "duration": 4.6}, {"text": "ce sont deux animaux, des mammif\u00e8res\nquadrup\u00e8des", "start": 706.36, "duration": 2.48}, {"text": "et ce sont les deux animaux domestiques\nles plus courants,", "start": 709.04, "duration": 2.2}, {"text": "le chien et le chat sont donc\ndes concepts proches.", "start": 711.44, "duration": 3.2}, {"text": "Alors l\u00e0 je vais avoir les teams\nchien et chat", "start": 714.84, "duration": 1.8}, {"text": "dans les commentaires, mais bon,\nc'est pas grave.", "start": 716.84, "duration": 1.04}, {"text": "Maintenant le mot \"Lynx\", on a probablement\nenvie qu'il soit aussi pr\u00e8s du chat,", "start": 718.08, "duration": 4.6}, {"text": "mais pas forc\u00e9ment si proche que \u00e7a du chien.", "start": 722.88, "duration": 2.92}, {"text": "Alors, si on est dans un plan on aura envie\nde le mettre ici par exemple", "start": 726.0, "duration": 3.48}, {"text": "et vous voyez qu'on a besoin\nd'une deuxi\u00e8me dimension.", "start": 729.68, "duration": 3.08}, {"text": "Et ici, on aurait par exemple le loup,", "start": 732.96, "duration": 2.44}, {"text": "le loup est au chien ce que\nle lynx est au chat,", "start": 735.6, "duration": 2.28}, {"text": "sa version sauvage plut\u00f4t que domestiqu\u00e9e.", "start": 738.08, "duration": 2.68}, {"text": "Donc si on voulait attribuer des num\u00e9ros\n\u00e0 ces quatre concepts,", "start": 740.96, "duration": 2.72}, {"text": "on n'utiliserait pas un seul nombre,", "start": 743.88, "duration": 1.44}, {"text": "mais plut\u00f4t deux pour chacun,\npour avoir les deux dimensions.", "start": 745.52, "duration": 2.96}, {"text": "Le chat serait repr\u00e9sent\u00e9\npar le vecteur (1.1),", "start": 748.68, "duration": 2.6}, {"text": "le chien (2.1), le lynx (1.2)\net le loup (2.2).", "start": 751.48, "duration": 5.0}, {"text": "Alors l\u00e0, \u00e7a marche bien parce que\nj'ai juste quatre mots,", "start": 756.68, "duration": 1.68}, {"text": "mais si j'en ai 50 000 c'est\nbeaucoup plus compliqu\u00e9.", "start": 758.56, "duration": 2.36}, {"text": "Pour que cette notion de proximit\u00e9 de sens\nsoit refl\u00e9t\u00e9e dans la proximit\u00e9 de vecteur,", "start": 761.12, "duration": 5.96}, {"text": "les repr\u00e9senter dans un plan,\n\u00e7a ne va pas suffire hein\u00a0!", "start": 767.28, "duration": 2.36}, {"text": "Je vais avoir besoin de beaucoup plus\nde dimensions, disons\u2026 300\u00a0!", "start": 769.84, "duration": 4.2}, {"text": "Et donc, \u00e0 chaque mot on aimerait associer", "start": 774.24, "duration": 2.0}, {"text": "non pas un ou deux nombres\nmais un vecteur de 300 nombres", "start": 776.44, "duration": 3.04}, {"text": "qui repr\u00e9senterait sa position\ndans l'espace des significations,", "start": 779.68, "duration": 4.32}, {"text": "avec une notion de proximit\u00e9 quand\ndeux mots semblent reli\u00e9s.", "start": 784.2, "duration": 3.8}, {"text": "Sur le papier, \u00e7a a l'air tr\u00e8s bien,\nmais en pratique \u00e7a semble", "start": 788.2, "duration": 1.84}, {"text": "un travail titanesque d'identifier\nles 300 dimensions", "start": 790.24, "duration": 3.0}, {"text": "et de qualifier chacun des 50 000 mot.", "start": 793.44, "duration": 2.56}, {"text": "Heureusement c'est un t\u00e2che qu'on peut\nautomatiser gr\u00e2ce \u00e0 un r\u00e9seau de neurones", "start": 796.2, "duration": 3.16}, {"text": "On va utiliser un algorithme capable\nde lire des millions de phrases", "start": 799.56, "duration": 4.04}, {"text": "et d'identifier par lui-m\u00eame les relations\nde proximit\u00e9", "start": 803.8, "duration": 3.04}, {"text": "de fa\u00e7on \u00e0 attribuer \u00e0 chaque mot\ndu dictionnaire", "start": 807.04, "duration": 2.24}, {"text": "un vecteur de coordonn\u00e9es dans l'espace\nde dimension 300.", "start": 809.48, "duration": 3.2}, {"text": "Pour la langue anglaise, c'est ce que font\npar exemple les algorithmes", "start": 812.88, "duration": 3.52}, {"text": "\"Word2vec\" cr\u00e9\u00e9 par Google, ou encore \"Glove\"\nd\u00e9velopp\u00e9 \u00e0 l'universit\u00e9 de Stanford.", "start": 816.6, "duration": 5.72}, {"text": "J'ai r\u00e9cup\u00e9r\u00e9 les donn\u00e9es de Glove,\nelles sont en acc\u00e8s libre,", "start": 822.52, "duration": 2.28}, {"text": "et j'ai regard\u00e9 les vecteurs associ\u00e9s\naux mots", "start": 825.0, "duration": 2.0}, {"text": "\"chat, chien, loup et lynx\" en anglais.", "start": 827.2, "duration": 2.2}, {"text": "Pour chacun de ces mots on a une liste\nde 300 nombres,", "start": 829.6, "duration": 3.16}, {"text": "un vecteur de dimension 300 dans\nl'espace des significations", "start": 832.96, "duration": 3.28}, {"text": "Les nombres en eux-m\u00eames, ne veulent\nstrictement rien dire,", "start": 836.44, "duration": 1.4}, {"text": "si vous me donnez un vecteur au hasard,", "start": 838.04, "duration": 1.44}, {"text": "je ne peux pas franchement vous dire\nce que \u00e7a repr\u00e9sente.", "start": 839.68, "duration": 2.12}, {"text": "en revanche, avec ces vecteurs on peut\ncalculer une notion de proximit\u00e9", "start": 842.0, "duration": 4.44}, {"text": "et on voit que la similarit\u00e9 entre\n\"chien\" et \"chat\" est de 80%,", "start": 846.64, "duration": 4.28}, {"text": "celle entre \"chat\" et \"lynx\" de 42 %,\n\"chien\" et \"loup\" 52%,", "start": 851.12, "duration": 3.8}, {"text": "mais \"chien\" et \"lynx\" seulement 33%.", "start": 855.12, "duration": 1.96}, {"text": "Alors que si on calcule la similarit\u00e9\navec un mot qui n'a rien \u00e0 voir,", "start": 857.28, "duration": 3.56}, {"text": "genre le mot \"processeur\" eh bien\non ne trouve", "start": 861.04, "duration": 2.24}, {"text": "que des valeurs de similarit\u00e9 tr\u00e8s faibles.", "start": 863.48, "duration": 1.64}, {"text": "D'apr\u00e8s les donn\u00e9es, la m\u00e9thode semble\nbien fonctionner", "start": 865.32, "duration": 3.4}, {"text": "et gr\u00e2ce \u00e0 tout cela on est donc capable\nd'associer \u00e0 chaque mot", "start": 868.92, "duration": 3.04}, {"text": "un vecteur dans un certain espace\nde significations.", "start": 872.16, "duration": 2.68}, {"text": "Ces vecteurs sont des nombres, et on va donc\npouvoir les donner \u00e0 des r\u00e9seaux de neurones.", "start": 875.04, "duration": 4.48}, {"text": "et si on en donne plusieurs \u00e0 la suite,\non va leur donner\u00a0: des phrases.", "start": 879.72, "duration": 2.681}, {"text": "[jingle]", "start": 882.601, "duration": 5.579}, {"text": "On l'a dit en intro, une des difficult\u00e9s\navec la compr\u00e9hension d'une phrase", "start": 888.42, "duration": 2.86}, {"text": "par une machine, que ce soit pour\nla traduire, la reformuler ou la compl\u00e9ter,", "start": 891.48, "duration": 3.2}, {"text": "c'est que les phrases n'ont pas\nde longueur fixe", "start": 894.88, "duration": 1.88}, {"text": "contrairement \u00e0 ce qu'on peut faire\nen reconnaissance d'image", "start": 896.96, "duration": 2.48}, {"text": "avec des images de taille donn\u00e9e.", "start": 899.64, "duration": 1.92}, {"text": "En principe on peut quand m\u00eame essayer\nd'utiliser le m\u00eame type de r\u00e9seau de neurones,", "start": 901.76, "duration": 3.52}, {"text": "les r\u00e9seaux de convolution, mais en pratique\nce n'est pas si efficace", "start": 905.48, "duration": 2.88}, {"text": "et on a trouv\u00e9 bien mieux et plus flexible\u00a0:\nles r\u00e9seaux r\u00e9currents.", "start": 908.56, "duration": 3.6}, {"text": "Pour comprendre le principe imaginez\nune phrase, disons\u00a0:", "start": 912.36, "duration": 2.24}, {"text": "\"Le chat mange goul\u00fbment la souris\" .", "start": 914.8, "duration": 2.96}, {"text": "Lisez cette phrase lentement, mot par mot.", "start": 917.96, "duration": 2.48}, {"text": "Qu'est-ce qui se passe dans votre t\u00eate\u00a0?", "start": 920.64, "duration": 2.0}, {"text": "Eh bien, \u00e0 chaque \u00e9tape vous allez avoir", "start": 922.84, "duration": 2.16}, {"text": "une compr\u00e9hension incompl\u00e8te de son sens,\nmais qui se modifie,", "start": 925.2, "duration": 3.48}, {"text": "se pr\u00e9cise \u00e0 chaque nouveau mot\nque vous lisez.", "start": 928.88, "duration": 2.0}, {"text": "\"Le\"\u00a0: OK, on ne sait pas grand chose.", "start": 931.08, "duration": 2.36}, {"text": "\"chat\"\u00a0: \u00e7a va parler d'un chat,\nmais on ne sait pas pourquoi.", "start": 933.64, "duration": 2.84}, {"text": "\"mange\"\u00a0: Ok, c'est un chat en train\nde manger, mais on ne sait pas quoi.", "start": 936.68, "duration": 3.72}, {"text": "\"goul\u00fbment\"\u00a0: Ah, le chat \u00e0 l'air de kiffer,\nmais on sait toujours pas quoi.", "start": 940.6, "duration": 4.2}, {"text": "\"la\" \"souris\"\u00a0: Ah, ben l\u00e0 finalement\non comprend\u00a0!", "start": 945.0, "duration": 3.48}, {"text": "Eh bien les r\u00e9seaux r\u00e9currents permettent\nen quelque sorte de mimer cette id\u00e9e de\u00a0:", "start": 948.68, "duration": 5.48}, {"text": "Je lis progressivement et j'ai\nune pens\u00e9e en t\u00eate", "start": 954.36, "duration": 2.4}, {"text": "qui se met \u00e0 jour \u00e0 chaque nouveau mot.", "start": 956.96, "duration": 2.64}, {"text": "Un r\u00e9seau r\u00e9current est constitu\u00e9\nd'une brique \u00e9l\u00e9mentaire", "start": 959.8, "duration": 2.24}, {"text": "qui prend en entr\u00e9e une pens\u00e9e\nainsi qu'un mot", "start": 962.24, "duration": 3.12}, {"text": "et qui donne en sortie la pens\u00e9e\nmodifi\u00e9e par ce mot.", "start": 965.56, "duration": 3.68}, {"text": "Et donc, pour analyser une phrase comme\n\"Le chat mange goul\u00fbment la souris\",", "start": 969.44, "duration": 3.6}, {"text": "eh bien on prend six copie du r\u00e9seau\nencha\u00een\u00e9es", "start": 973.24, "duration": 2.4}, {"text": "les unes \u00e0 la suite des autres sur\nchacun des mots de la phrase.", "start": 975.84, "duration": 4.16}, {"text": "L\u00e0, vous allez me dire\u00a0:\n\"c'est quoi une pens\u00e9e\u00a0? \"", "start": 980.2, "duration": 2.56}, {"text": "On a vu comment repr\u00e9senter un mot\npar une suite de nombres,", "start": 982.96, "duration": 2.4}, {"text": "avec un vecteur de dimension 300 par exemple,\nmais une pens\u00e9e, comment on va faire\u00a0?", "start": 985.56, "duration": 5.08}, {"text": "Eh ben, on va faire pareil, on va dire\nqu'une pens\u00e9e est aussi un vecteur,", "start": 990.84, "duration": 4.24}, {"text": "une grande suite de nombres, on va juste\nprendre une taille encore plus grande,", "start": 995.28, "duration": 3.52}, {"text": "disons de dimension 1 000,", "start": 999.0, "duration": 1.48}, {"text": "oui parce qu'une pens\u00e9e c'est plus riche\nqu'un simple mot,", "start": 1000.68, "duration": 2.76}, {"text": "donc il faudra bien 1 000 nombres r\u00e9els\npour d\u00e9crire un vecteur de pens\u00e9e.", "start": 1003.64, "duration": 3.92}, {"text": "Ce vecteur, techniquement\non appelle \u00e7a plut\u00f4t\u00a0:", "start": 1007.76, "duration": 1.64}, {"text": "\"le vecteur d'\u00e9tat interne du r\u00e9seau\".", "start": 1009.6, "duration": 2.16}, {"text": "C'est un des chercheur du domaine,\nGeoffrey Hinton,", "start": 1011.96, "duration": 2.12}, {"text": "qui avait propos\u00e9 le terme\nde \"vecteur de pens\u00e9e\".", "start": 1014.28, "duration": 2.48}, {"text": "Je crois qu'il n'est pas tellement utilis\u00e9\ndans les publications scientifiques,", "start": 1016.96, "duration": 2.68}, {"text": "mais je troue que \u00e7a colle assez bien\npour expliquer l'id\u00e9e comme \u00e7a.", "start": 1019.84, "duration": 2.56}, {"text": "Par contre, comme pour les vecteurs\nqui repr\u00e9sentent les mots,", "start": 1022.6, "duration": 3.92}, {"text": "ces vecteurs de pens\u00e9e sont des constructions\ninterm\u00e9diaires du r\u00e9seau", "start": 1026.72, "duration": 3.16}, {"text": "qui n'ont aucun sens pour nous les humains,", "start": 1030.08, "duration": 2.08}, {"text": "ce sont des listes de nombres\nqu'on ne sait pas interpr\u00e9ter.", "start": 1032.36, "duration": 2.92}, {"text": "C'est comme si la pens\u00e9e \u00e9tait cod\u00e9e\npar ce vecteur.", "start": 1035.48, "duration": 2.92}, {"text": "Bon, pour r\u00e9sumer\u00a0:", "start": 1038.6, "duration": 0.72}, {"text": "une unit\u00e9 r\u00e9currente est donc comme\nune petite machine", "start": 1039.52, "duration": 2.16}, {"text": "qui va prendre en entr\u00e9e un vecteur\nde pens\u00e9e, souvent not\u00e9 \"h\"", "start": 1041.88, "duration": 3.56}, {"text": "et un vecteur de mot \"x\" et donner\nen sortie un nouveau vecteur de pens\u00e9e.", "start": 1045.64, "duration": 4.76}, {"text": "Bien s\u00fbr, souvenez-vous qu'on parle\nd'un r\u00e9seau de neurones", "start": 1050.6, "duration": 2.08}, {"text": "donc dans le d\u00e9tail cette machine c'est\nune fonction param\u00e9tr\u00e9e par des poids", "start": 1052.88, "duration": 3.84}, {"text": "qu'on note toujours \"W\" et ce sont ces poids\nqui seront r\u00e9gl\u00e9s", "start": 1056.92, "duration": 4.0}, {"text": "durant la phase d'entra\u00eenement du r\u00e9seau.", "start": 1061.12, "duration": 2.4}, {"text": "Bon, donc l'encha\u00eenement d'unit\u00e9s r\u00e9currentes\nsur les mots d'une phrase", "start": 1063.72, "duration": 2.72}, {"text": "permet donc de produire un vecteur\nde pens\u00e9e \u00e0 partir de cette phrase", "start": 1066.64, "duration": 3.76}, {"text": "et comme le vecteur de pens\u00e9e ressemble\n\u00e0 une version cod\u00e9e de la phrase", "start": 1070.6, "duration": 3.2}, {"text": "on appelle cet ensemble\u00a0: un \"encodeur\".", "start": 1074.0, "duration": 2.72}, {"text": "Maintenant, ce qu'on va faire de ce qui sort\nde l'encodeur", "start": 1076.92, "duration": 1.92}, {"text": "va d\u00e9pendre du type de t\u00e2che\nqu'on cherche \u00e0 ex\u00e9cuter.", "start": 1079.04, "duration": 2.52}, {"text": "Prenons \u00e0 nouveau notre probl\u00e8me simple\nde la classification", "start": 1081.76, "duration": 3.12}, {"text": "des sentiments exprim\u00e9s par une phrase,", "start": 1085.08, "duration": 2.44}, {"text": "la phrase\u00a0: \"Cette vid\u00e9o est loin d'\u00eatre\naussi bonne que la pr\u00e9c\u00e9dente\"", "start": 1087.72, "duration": 3.24}, {"text": "va \u00eatre encod\u00e9e sous la forme d'un vecteur\nde pens\u00e9e", "start": 1091.16, "duration": 3.68}, {"text": "et ce vecteur n'est pas interpr\u00e9table\npar un humain,", "start": 1095.04, "duration": 1.6}, {"text": "il faut donc ensuite le donner \u00e0\nun autre r\u00e9seau", "start": 1096.84, "duration": 2.08}, {"text": "dont le travail va \u00eatre de classifier\nla phrase", "start": 1099.12, "duration": 2.16}, {"text": "soit en positif soit en n\u00e9gatif par exemple.", "start": 1101.48, "duration": 3.16}, {"text": "Ce deuxi\u00e8me r\u00e9seau ne sera pas\nune unit\u00e9 r\u00e9currente,", "start": 1104.84, "duration": 2.0}, {"text": "ce sera une structure diff\u00e9rente\nqui prend en entr\u00e9e un vecteur de pens\u00e9e", "start": 1107.04, "duration": 3.64}, {"text": "et donne par exemple en sortie la probabilit\u00e9\n\"y\" que la phrase soit positive ou n\u00e9gative.", "start": 1110.88, "duration": 5.84}, {"text": "Bien entendu ce r\u00e9seau va lui aussi poss\u00e9der\nses poids \"W\" qu'il va falloir r\u00e9gler.", "start": 1116.92, "duration": 4.92}, {"text": "Le r\u00e9glage des poids se fait conjointement\navec ceux du r\u00e9seau r\u00e9current", "start": 1122.04, "duration": 3.08}, {"text": "durant la phase d'apprentissage,\non va prendre des milliers de phrases", "start": 1125.32, "duration": 3.2}, {"text": "d\u00e9j\u00e0 classifi\u00e9es \u00e0 la main, on va les montrer\n\u00e0 notre r\u00e9seau complet", "start": 1128.72, "duration": 3.8}, {"text": "et on va esp\u00e9rer qu'il apprenne \u00e0 classifier\nlui m\u00eame les phrases.", "start": 1132.72, "duration": 3.24}, {"text": "Alors prenons maintenant la question\nde la traduction, c'est plus compliqu\u00e9", "start": 1136.16, "duration": 3.24}, {"text": "car en sortie on ne doit pas juste\ndonner un vecteur \"y\",", "start": 1139.6, "duration": 2.88}, {"text": "mais tout une suite de mot et\nles deux phrases n'auront \u00e0 priori", "start": 1142.68, "duration": 3.6}, {"text": "pas la m\u00eame longueur dans les deux langues.", "start": 1146.48, "duration": 1.36}, {"text": "Par exemple une traduction du proverbe\u00a0:\n\"All is fair in love and war\"", "start": 1148.04, "duration": 4.12}, {"text": "\u00e7a pourrait \u00eatre\u00a0: \"En amour comme \u00e0 la guerre,\ntous les coups sont permis\",", "start": 1152.36, "duration": 4.0}, {"text": "7 mots d'un c\u00f4t\u00e9, 11 de l'autre, donc\non ne voudra surtout pas traduire mot \u00e0 mot.", "start": 1156.56, "duration": 4.28}, {"text": "En fait on va faire l'inverse\nde ce qu'on a fait pour encoder les phrases,", "start": 1161.04, "duration": 3.44}, {"text": "on va utiliser un r\u00e9seau r\u00e9current d\u00e9codeur.", "start": 1164.68, "duration": 2.4}, {"text": "Je vous ai dit que le r\u00e9seau encodeur\nproduisait \u00e0 la fin", "start": 1167.28, "duration": 2.6}, {"text": "un vecteur de pens\u00e9e sens\u00e9 repr\u00e9senter\nnum\u00e9riquement le sens de la phrase.", "start": 1170.08, "duration": 3.6}, {"text": "Eh bien maintenant, on va utiliser\nune autre unit\u00e9 r\u00e9currente diff\u00e9rente", "start": 1173.88, "duration": 3.96}, {"text": "qu'on va encha\u00eener pour produire\nprogressivement les mots de la traduction.", "start": 1178.04, "duration": 3.28}, {"text": "Cette unit\u00e9-l\u00e0 prend en entr\u00e9e\nle vecteur de pens\u00e9e", "start": 1181.52, "duration": 3.8}, {"text": "et produit en sortie un mot\ndans l'autre langue ainsi", "start": 1185.52, "duration": 2.96}, {"text": "que le vecteur de pens\u00e9e mis \u00e0 jour,", "start": 1188.68, "duration": 2.6}, {"text": "et le vecteur de pens\u00e9e va maintenant\nen quelque sorte,", "start": 1191.48, "duration": 2.04}, {"text": "repr\u00e9senter l'\u00e9tat de ce\nqu'il reste \u00e0 traduire.", "start": 1193.72, "duration": 2.24}, {"text": "Par exemple en plein milieu de la traduction\nde\u00a0: All is fair in love and war\"", "start": 1196.16, "duration": 4.0}, {"text": "il pourrait repr\u00e9senter le concept de\u00a0:", "start": 1200.36, "duration": 1.56}, {"text": "\"je dois encore traduire \"all is fair\",\nmais pour \"in love and war\" c'est bon.", "start": 1202.12, "duration": 5.44}, {"text": "\u00c9videmment on a toujours la m\u00eame situation\nqui est qu'avec un r\u00e9seau de neurones,", "start": 1207.76, "duration": 3.0}, {"text": "ce qu'on aura en sortie, ce ne sont pas\ndes mots mais des nombres,", "start": 1210.96, "duration": 2.44}, {"text": "qu'il faudra interpr\u00e9ter comme\ndes probabilit\u00e9 d'avoir tel ou tel mot.", "start": 1213.6, "duration": 3.48}, {"text": "Et bien s\u00fbr, le r\u00e9seau devra aussi \u00eatre\ncapable de produire en sortie", "start": 1217.28, "duration": 4.2}, {"text": "un symbole qui dit\u00a0: \"stop, la traduction\nest termin\u00e9e\".", "start": 1221.68, "duration": 2.56}, {"text": "Pour de la traduction on aura donc besoin\nd'entra\u00eener les deux r\u00e9seaux r\u00e9currents,", "start": 1224.44, "duration": 4.12}, {"text": "l'encodeur et le d\u00e9codeur, et ce\nde fa\u00e7on conjointe", "start": 1228.76, "duration": 2.56}, {"text": "en leur pr\u00e9sentant des phrases traduites\ndans les deux langues.", "start": 1231.52, "duration": 2.72}, {"text": "On peux utiliser le m\u00eame genre de technique\npour ce qui est un des probl\u00e8mes", "start": 1234.44, "duration": 2.84}, {"text": "les plus spectaculaires des applications\ndu traitement du langage naturel\u00a0:", "start": 1237.48, "duration": 3.32}, {"text": "la compl\u00e9tion de texte.", "start": 1241.0, "duration": 1.56}, {"text": "L'id\u00e9e est simple, vous commencez\n\u00e0 \u00e9crire un texte", "start": 1242.56, "duration": 2.56}, {"text": "et vous laissez un algorithme le compl\u00e9ter\npour vous autant que vous voulez.", "start": 1245.32, "duration": 3.6}, {"text": "Le principe utilis\u00e9 est un peu similaire\n\u00e0 celui de la traduction,", "start": 1254.0, "duration": 3.76}, {"text": "mais on demande cette fois\nau r\u00e9seau d\u00e9codeur", "start": 1257.96, "duration": 2.48}, {"text": "de tenter de pr\u00e9dire le prochain mot,", "start": 1260.64, "duration": 2.04}, {"text": "il ne cherche pas \u00e0 traduire la pens\u00e9e,\nmais \u00e0 la compl\u00e9ter", "start": 1262.88, "duration": 2.28}, {"text": "de la fa\u00e7on qu'il estime la plus probable.", "start": 1265.36, "duration": 2.48}, {"text": "Malheureusement cette m\u00e9thode du r\u00e9seau\nr\u00e9current que je viens de vous d\u00e9crire", "start": 1268.04, "duration": 2.76}, {"text": "si vous l'appliquez tel quel, \u00e7a ne va pas\nforc\u00e9ment si bien fonctionner,", "start": 1271.0, "duration": 3.96}, {"text": "il y a une difficult\u00e9 qui est\nla gestion de la m\u00e9moire.", "start": 1275.16, "duration": 3.48}, {"text": "Imaginez la phrase\u00a0:", "start": 1278.64, "duration": 1.92}, {"text": "Vous avez certainement devin\u00e9 que le mot\nqui vient apr\u00e8s c'est\u00a0: \"anglais\",", "start": 1288.0, "duration": 5.0}, {"text": "mais si je demande \u00e0 un r\u00e9seau r\u00e9current\nde compl\u00e9ter cette phrase,", "start": 1293.2, "duration": 2.68}, {"text": "il va falloir qu'il ait gard\u00e9\nune bonne m\u00e9moire", "start": 1296.08, "duration": 2.16}, {"text": "du tout premier mot \"Boston\"\npour la compl\u00e9ter correctement", "start": 1298.44, "duration": 3.32}, {"text": "Or, quand on encha\u00eene les unit\u00e9s r\u00e9currentes\ndans un encodeur,", "start": 1301.96, "duration": 2.76}, {"text": "le dernier mot aura bien plus d'impact\nque le premier", "start": 1304.92, "duration": 2.6}, {"text": "sur le vecteur de pens\u00e9e qui sort\nde l'encodeur", "start": 1307.72, "duration": 2.4}, {"text": "et donc la m\u00e9moire des premiers mots", "start": 1310.32, "duration": 1.68}, {"text": "se trouvera d'autant plus dilu\u00e9e\nque la phrase est longue.", "start": 1312.2, "duration": 3.64}, {"text": "Il existe plusieurs solutions techniques\npour essayer de limiter cet effet,", "start": 1316.04, "duration": 2.96}, {"text": "Par exemple\u00a0: encoder une phrase\nen la lisant dans les deux sens", "start": 1319.2, "duration": 3.12}, {"text": "ou bien conserver, en plus du vecteur d'\u00e9tat,\nun autre vecteur de m\u00e9moire", "start": 1322.52, "duration": 3.84}, {"text": "qui se dilue moins, c'est le principe\ndes r\u00e9seaux dits LFTM", "start": 1326.56, "duration": 3.44}, {"text": "pour \"Long Short Term Memory\",", "start": 1330.2, "duration": 1.88}, {"text": "mais il y a aussi les GRU pour\nGated R\u00e9current Unit\".", "start": 1332.28, "duration": 3.28}, {"text": "Je ne vais pas d\u00e9tailler leur fonctionnement,", "start": 1335.76, "duration": 0.96}, {"text": "mais ils sont bas\u00e9s sur un certain nombre\nde fonctions", "start": 1336.92, "duration": 2.52}, {"text": "qui cherchent \u00e0 imiter ce qu'on pourrait\npenser \u00eatre", "start": 1339.64, "duration": 2.52}, {"text": "le fonctionnement de notre cerveau\ncomme la capacit\u00e9 \u00e0 oublier ou retenir", "start": 1342.36, "duration": 4.24}, {"text": "s\u00e9lectivement certaines informations\nquand elles nous sont pr\u00e9sent\u00e9es.", "start": 1346.8, "duration": 3.2}, {"text": "Mais les progr\u00e8s les plus significatifs\nont \u00e9t\u00e9 obtenus avec ce qu'on appelle", "start": 1350.2, "duration": 3.64}, {"text": "le \"m\u00e9canisme d'attention\", qui permet\nau r\u00e9seau de se focaliser", "start": 1354.04, "duration": 3.88}, {"text": "sur certaines parties de la phrase d'entr\u00e9e\npour produire sa sortie.", "start": 1358.12, "duration": 3.16}, {"text": "Une fa\u00e7on de le faire est de donner\nau d\u00e9codeur,", "start": 1361.48, "duration": 1.96}, {"text": "non pas juste le vecteur de pens\u00e9e final,", "start": 1363.64, "duration": 2.24}, {"text": "mais tous les vecteurs de pens\u00e9es\ninterm\u00e9diaires produits par l'encodeur,", "start": 1366.08, "duration": 3.68}, {"text": "avec des structures qui vont les traiter\npour en extraire des informations de contexte.", "start": 1369.96, "duration": 4.8}, {"text": "Mais la r\u00e9volution la plus r\u00e9cente\ndans le domaine date de 2017", "start": 1374.96, "duration": 3.48}, {"text": "o\u00f9 des chercheurs ont publi\u00e9 un article\nscientifique intitul\u00e9\u00a0:", "start": 1378.64, "duration": 2.8}, {"text": "\"Attention is all you need\",", "start": 1381.64, "duration": 2.16}, {"text": "dans cette publication, ils introduisent\nune nouvelle structure de r\u00e9seau", "start": 1384.0, "duration": 3.12}, {"text": "qui conserve le m\u00e9canisme d'attention,\nmais se d\u00e9barrasse des r\u00e9seaux r\u00e9currents.", "start": 1387.32, "duration": 4.04}, {"text": "On donne cette fois toute la phrase\nd'un coup", "start": 1391.56, "duration": 1.84}, {"text": "en encodant la position de chaque mot,\net le r\u00e9seau va calculer l'attention", "start": 1393.6, "duration": 4.12}, {"text": "entre les diff\u00e9rentes parties de la phrase.", "start": 1397.92, "duration": 1.8}, {"text": "Dans mon exemple avec Boston, le r\u00e9seau\nse rendrait par exemple compte", "start": 1399.92, "duration": 2.32}, {"text": "qu'il y a un lien entre les mots \"Boston\"\net \"parler\u2026 anglais\",", "start": 1402.44, "duration": 3.72}, {"text": "m\u00eame si les mots sont tr\u00e8s \u00e9loign\u00e9s\ndans la phrase.", "start": 1406.36, "duration": 2.4}, {"text": "La nouvelle architecture ainsi cr\u00e9\u00e9e\ns'appelle un \"transformeur\"", "start": 1408.96, "duration": 3.0}, {"text": "et les chercheurs d'OpenAI l'on utilis\u00e9e\npour cr\u00e9er le mod\u00e8le de langage GPT", "start": 1412.16, "duration": 4.2}, {"text": "qui en est actuellement \u00e0 sa troisi\u00e8me\nit\u00e9ration, GPT3.", "start": 1416.56, "duration": 3.16}, {"text": "Cette version a \u00e9t\u00e9 entrain\u00e9e sur des dizaines\nde milliard de phrases en anglais", "start": 1419.92, "duration": 4.08}, {"text": "et il fallait bien \u00e7a parce que GPT3\nposs\u00e9derait", "start": 1424.2, "duration": 2.28}, {"text": "175 milliards de poids \u00e0 ajuster\ndans son r\u00e9seau.", "start": 1426.68, "duration": 3.24}, {"text": "L'id\u00e9e des transformeurs a \u00e9norm\u00e9ment\ninspir\u00e9 les chercheurs du domaine", "start": 1430.12, "duration": 2.8}, {"text": "et c'est la m\u00eame technique que l'on retrouve\nderri\u00e8re les mod\u00e8les de langage BERT", "start": 1433.12, "duration": 3.24}, {"text": "d\u00e9velopp\u00e9 par Google, mais aussi CamenBERT\nun mod\u00e8le en fran\u00e7ais", "start": 1436.56, "duration": 3.72}, {"text": "d\u00e9velopp\u00e9 conjointement par Facebook\net l'INRIA.", "start": 1440.48, "duration": 2.4}, {"text": "Dans un autre genre, il y a quelque temps\ndans une vid\u00e9o", "start": 1443.08, "duration": 1.68}, {"text": "je vous avais parl\u00e9 du traitement\ndu probl\u00e8me du repliement des prot\u00e9ines,", "start": 1444.96, "duration": 2.76}, {"text": "eh bien on y retrouve aussi les transformeurs.", "start": 1447.92, "duration": 1.96}, {"text": "Sinon, petit rebondissement,", "start": 1450.08, "duration": 1.12}, {"text": "alors que j'\u00e9tais en train de terminer\nd'\u00e9crire cette vid\u00e9o,", "start": 1451.4, "duration": 2.44}, {"text": "un tout nouveau mod\u00e8le de langage\nen Fran\u00e7ais \u00e0 \u00e9t\u00e9 publi\u00e9\u00a0: C\u00e9dille.AI", "start": 1454.04, "duration": 4.72}, {"text": "et vous pouvez aller le tester librement\nsur leur site,", "start": 1458.96, "duration": 2.12}, {"text": "notamment pour faire de la compl\u00e9tion\nde texte,", "start": 1461.28, "duration": 1.84}, {"text": "\u00e7a fonctionne de fa\u00e7on tr\u00e8s spectaculaire.", "start": 1463.32, "duration": 3.52}, {"text": "\u00c9videmment, quand on voit tout \u00e7a on pense\nau test de Turing", "start": 1467.04, "duration": 2.36}, {"text": "et on peut se demander si ces algorithmes\n\"comprennent\" r\u00e9ellement ce qu'il racontent.", "start": 1469.6, "duration": 4.24}, {"text": "Ce qui ressort assez clairement c'est que\nles r\u00e9ponses sont le plus souvent", "start": 1474.04, "duration": 2.68}, {"text": "vraiment plausibles, mais on voit que\nl'algorithme manque souvent de coh\u00e9rence,", "start": 1476.92, "duration": 3.8}, {"text": "il n'a pas de mod\u00e8le mental du monde\nqu'il d\u00e9crit.", "start": 1480.92, "duration": 3.08}, {"text": "\u00c7a se voit par exemple avec \"AI Dungeon\"\nun algorithme bas\u00e9 sur GPT", "start": 1484.2, "duration": 3.28}, {"text": "qui vous propose de faire du jeu de r\u00f4le\nen mode texte,", "start": 1487.68, "duration": 3.0}, {"text": "vous tapez ce que vous voulez et le ma\u00eetre\ndu jeu vous r\u00e9pond en compl\u00e9tant l'histoire", "start": 1490.88, "duration": 3.92}, {"text": "et c'est assez facile de faire des choses\nincoh\u00e9rentes du genre\u00a0:", "start": 1495.0, "duration": 2.6}, {"text": "\"Je jette mon \u00e9p\u00e9e au fond du lac\"", "start": 1497.8, "duration": 1.72}, {"text": "et ensuite, ben j'utilise mon \u00e9p\u00e9e \u00e0 nouveau,", "start": 1499.72, "duration": 2.6}, {"text": "et le ma\u00eetre du jeu virtuel\nn'y voit que du feu", "start": 1502.52, "duration": 2.0}, {"text": "alors qu'avec un vrai ma\u00eetre du jeu\n\u00e7a ne passerait pas hein.", "start": 1504.72, "duration": 3.0}, {"text": "Mais pour des t\u00e2ches relativement automatis\u00e9es\ncomme la traduction,", "start": 1507.92, "duration": 2.72}, {"text": "les chatbox ou le fait de compl\u00e9ter\ndes textes simples,", "start": 1510.84, "duration": 2.84}, {"text": "eh bien ces algorithmes de compl\u00e9tion\nde texte peuvent largement suffire.", "start": 1513.88, "duration": 3.04}, {"text": "Si vous faites de la programmation\nje vous invite aussi \u00e0 regarder", "start": 1517.12, "duration": 2.72}, {"text": "ce qui se fait en compl\u00e9tion de code,\nc'est assez balaise.", "start": 1520.04, "duration": 2.16}, {"text": "Bien s\u00fbr, quand on les utilise\npour g\u00e9n\u00e9rer des textes,", "start": 1522.4, "duration": 3.24}, {"text": "tous ces mod\u00e8les posent tr\u00e8s vite\ndes questions", "start": 1525.84, "duration": 2.08}, {"text": "li\u00e9es notamment aux biais des textes\nqui ont \u00e9t\u00e9 utilis\u00e9s pour les entrain\u00e9s.", "start": 1528.12, "duration": 4.28}, {"text": "Je ne vais pas vous montrer d'exemples,\nmais on peut assez vite se rendre compte", "start": 1532.6, "duration": 2.56}, {"text": "du fait que ces mod\u00e8les reproduisent\nsans surprise les biais racistes ou sexistes", "start": 1535.36, "duration": 4.72}, {"text": "qu'on trouve dans les textes qui ont servi\n\u00e0 leur construction", "start": 1540.28, "duration": 2.68}, {"text": "Il faudrait pas mal de temps\npour en parler bien,", "start": 1543.16, "duration": 1.4}, {"text": "donc je vous renvoie sur la cha\u00eene\n\"Science for all\"", "start": 1544.76, "duration": 1.52}, {"text": "o\u00f9 L\u00ea aborde souvent cette question.", "start": 1546.48, "duration": 2.12}, {"text": "Voil\u00e0, c'est tout pour aujourd'hui,\npour ceux qui veulent creuser,", "start": 1548.8, "duration": 2.28}, {"text": "plus de d\u00e9tails sont disponible dans\nle billet de blog, comme toujours.", "start": 1551.28, "duration": 2.68}, {"text": "Partagez la vid\u00e9o, histoire d'en faire\nprofiter tout le monde, abonnez-vous,", "start": 1554.16, "duration": 2.88}, {"text": "mettez des pouces et des cloches en offrande\n\u00e0 l'algorithme de Youtube", "start": 1557.24, "duration": 3.08}, {"text": "et on se retrouve tr\u00e8s vite\npour de nouvelles vid\u00e9o, \u00e0 bient\u00f4t\u00a0!", "start": 1560.52, "duration": 2.72}, {"text": "\u2013 Sous-titrage\u00a0: Le Crayon d'oreille -", "start": 1563.44, "duration": 3.64}]}